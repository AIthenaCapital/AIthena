{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dependencies \n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date  Price       RSI  Stedev from 20 MA  MACD n.f  50MA_N.F.  \\\n",
      "0 2011-12-16   3.25  0.514151           0.591527  1.594689   0.500194   \n",
      "1 2011-12-18   3.25  0.443243           0.516482  1.489778   0.571086   \n",
      "2 2011-12-19   3.50  0.511962           1.311777  1.473728   1.266368   \n",
      "3 2011-12-20   4.75  0.822695           3.461711  1.840524   3.831441   \n",
      "4 2011-12-21   4.38  0.753247           2.180044  1.969366   2.760808   \n",
      "\n",
      "   20D PMO  35D PMO        ADX  actions  y-hat  Unnamed: 11  Unnamed: 12  \n",
      "0    3.270     0.59  69.772809      NaN      2            1  2157.000000  \n",
      "1    3.690     0.46  70.038037      NaN      2            1     0.912437  \n",
      "2    4.275     0.67  70.475308      NaN      2            1          NaN  \n",
      "3    5.140     1.55  68.503186      NaN      2            1          NaN  \n",
      "4    5.910     1.28  66.671929      NaN      2            1          NaN  \n"
     ]
    }
   ],
   "source": [
    "# importing data using pandas \n",
    "dfz = pd.read_excel('BTC daily_database.xlsx', sheet_name=0)\n",
    "# testing the input is correct or not\n",
    "print(dfz.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomize sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffler() will read the data and randomly organizes it \n",
    "def shuffler(filename):\n",
    "  # Read an Excel table into a pandas DataFrame\n",
    "  # takes the first sheet and header\n",
    "    \n",
    "  dfs = pd.read_excel(filename, sheet_name=0, header=0)\n",
    "  # return the pandas dataframe\n",
    "  # np.random.permutation shuffles the data points \n",
    "  # dfs will clean the data by placing NaN at x-features that have no data \n",
    "  return dfs.reindex(np.random.permutation(dfs.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date   Price       RSI  Stedev from 20 MA  MACD n.f  50MA_N.F.  \\\n",
      "1029 2014-10-11  360.85  0.359489          -0.474948 -0.952752  -1.309753   \n",
      "1789 2016-11-12  716.39  0.575791           0.773393  0.885070   1.536607   \n",
      "937  2014-07-11  616.87  0.632799           0.185397 -0.156093   0.241928   \n",
      "459  2013-03-20   59.46  0.831453           2.462333  1.736448   2.584392   \n",
      "640  2013-09-17  126.28  0.455556           0.551945  0.332576   1.261497   \n",
      "\n",
      "      20D PMO  35D PMO        ADX  actions  y-hat  Unnamed: 11  Unnamed: 12  \n",
      "1029   -7.545    -0.74  13.655946      NaN      2            1          NaN  \n",
      "1789    4.185     0.46  12.940578      NaN      2            1          NaN  \n",
      "937     3.080    -0.16  19.305360      NaN      2            1          NaN  \n",
      "459    22.215     2.58  16.822374      NaN      2            1          NaN  \n",
      "640     8.200     0.84  17.457557      NaN      2            1          NaN  \n"
     ]
    }
   ],
   "source": [
    "# randomizes the data and saves it in df\n",
    "df = shuffler('BTC daily_database.xlsx')\n",
    "\n",
    "# prints the first 5 rows of the data table\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputX shape: (7, 2363)\n",
      "number of training samples = 2363\n",
      "number of variables = 7\n",
      "[[  0.35948917   0.57579073   0.63279896 ...,   0.73874488   0.40005344\n",
      "    0.74928894]\n",
      " [ -0.47494778   0.77339282   0.18539704 ...,   1.08998876  -0.08512263\n",
      "    1.161066  ]\n",
      " [ -0.95275179   0.88507032  -0.15609302 ...,   1.1342035   -0.20952482\n",
      "    1.66894123]\n",
      " ..., \n",
      " [ -7.545        4.185        3.08       ...,  -0.155        1.745       10.2       ]\n",
      " [ -0.74         0.46        -0.16       ...,   0.37         0.84         1.55      ]\n",
      " [ 13.65594636  12.94057801  19.30535952 ...,  16.33373387  29.5097828\n",
      "   26.96992104]]\n",
      "(1, 2363)\n"
     ]
    }
   ],
   "source": [
    "# converts to numpy array using as_matrix()\n",
    "# use iloc() to get location \n",
    "inputX = df.iloc[:,2:9 ].as_matrix()\n",
    "\n",
    "# transposes inputX\n",
    "inputX = inputX.T\n",
    "\n",
    "# converts to numpy array using as_matrix()\n",
    "# use iloc() to get location \n",
    "inputY = df.iloc[:, 10:11].as_matrix()\n",
    "\n",
    "# transposes inputY\n",
    "inputY = inputY.T\n",
    "\n",
    "print(\"inputX shape: \" + str(inputX.shape))\n",
    "print(\"number of training samples = \"+ str(inputX.shape[1]))\n",
    "print(\"number of variables = \" + str(inputX.shape[0]))\n",
    "print(inputX)\n",
    "print(inputY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 2, ..., 2, 2, 2]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperating to train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX's shape: (7, 1893)\n",
      "testX's shape: (7, 470)\n",
      "trainX's shape: (1, 1893)\n",
      "testY's shape: (1, 470)\n"
     ]
    }
   ],
   "source": [
    "# selects trainning data \n",
    "trainX = inputX[:, : -470]\n",
    "trainY = inputY[:, : -470]\n",
    "\n",
    "# selects test data \n",
    "testX = inputX[:, -470: ]\n",
    "testY = inputY[:, -470: ]\n",
    "\n",
    "# verifies the shapes \n",
    "print(\"trainX's shape: \" + str(trainX.shape))\n",
    "print(\"testX's shape: \" + str(testX.shape))\n",
    "print(\"trainX's shape: \" + str(trainY.shape))\n",
    "print(\"testY's shape: \" + str(testY.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer size inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_x's shape = 7\n",
      "first layer(n_h)'s shape = 10\n",
      "n_y's output = 1\n"
     ]
    }
   ],
   "source": [
    "# size of input layer\n",
    "n_x = inputX.shape[0]\n",
    "\n",
    "# amount of hidden layers\n",
    "n_h = 10\n",
    "\n",
    "# output layer \n",
    "n_y = inputY.shape[0]\n",
    "\n",
    "print(\"n_x's shape = \" + str(n_x))\n",
    "print(\"first layer(n_h)'s shape = \" + str(n_h))\n",
    "print(\"n_y's output = \" + str(n_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create placeholder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the placeholders for the tensorflow session.\n",
    "def create_placeholders(n_x, n_y):\n",
    "    \n",
    "    # creates placholder for x and y that batch size can be any size\n",
    "    X = tf.placeholder(tf.float32, shape = [n_x,None])\n",
    "    Y = tf.placeholder(tf.float32, shape = [n_y, 1, None])  \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"Placeholder_2:0\", shape=(7, ?), dtype=float32)\n",
      "(7, ?)\n",
      "Y = Tensor(\"Placeholder_3:0\", shape=(1, 1, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X, Y = create_placeholders(n_x,n_y)\n",
    "print (\"X = \" + str(X))\n",
    "print(X.shape)\n",
    "print (\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Initializes weight parameters to build a neural network with tensorflow  \n",
    "def initialize_parameters(n_x, n_h):\n",
    "    #tf.set_random_seed()\n",
    "    \n",
    "    # Layer 1 (Input Layer)\n",
    "    W1 = tf.get_variable(\"W1\", [n_h,n_x], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    b1 = tf.get_variable(\"b1\", [n_h,1], initializer = tf.zeros_initializer())\n",
    "    \n",
    "    # Layer 2 (10 neurons)\n",
    "    W2 = tf.get_variable(\"W2\", [10, n_h], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    b2 = tf.get_variable(\"b2\", [10, 1], initializer = tf.zeros_initializer())\n",
    "    \n",
    "    # Layer 3 (25 neurons)\n",
    "    W3 = tf.get_variable(\"W3\", [25, 10], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    b3 = tf.get_variable(\"b3\", [25, 1], initializer = tf.zeros_initializer())\n",
    "    \n",
    "    # Layer 4 (10 neurons)\n",
    "    W4 = tf.get_variable(\"W4\", [10, 25], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    b4 = tf.get_variable(\"b4\", [10,1], initializer = tf.zeros_initializer())\n",
    "    \n",
    "    # Layer 5 (5 neurons)\n",
    "    W5 = tf.get_variable(\"W5\", [5, 10], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    b5 = tf.get_variable(\"b5\", [5,1], initializer = tf.zeros_initializer())\n",
    "    \n",
    "    #W6 = tf.get_variable(\"W6\", [5, 10], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    #b6 = tf.get_variable(\"b6\", [5,1], initializer = tf.zeros_initializer())\n",
    "    #W7 = tf.get_variable(\"W7\", [5, 10], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    #b7 = tf.get_variable(\"b7\", [5,1], initializer = tf.zeros_initializer())\n",
    "    \n",
    "    # saves weights and bias for layers as a dictionary \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3,\n",
    "                  \"W4\": W4,\n",
    "                  \"b4\": b4,\n",
    "                  \"W5\": W5,\n",
    "                  \"b5\": b5}\n",
    "                  #\"W6\": W6,\n",
    "                  #\"b6\": b6,\n",
    "                  #\"W7\": W7,\n",
    "                  #\"b7\": b7}\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = <tf.Variable 'W1:0' shape=(10, 7) dtype=float32_ref>\n",
      "b1 = <tf.Variable 'b1:0' shape=(10, 1) dtype=float32_ref>\n",
      "W2 = <tf.Variable 'W2:0' shape=(10, 10) dtype=float32_ref>\n",
      "b2 = <tf.Variable 'b2:0' shape=(10, 1) dtype=float32_ref>\n",
      "W3 = <tf.Variable 'W3:0' shape=(25, 10) dtype=float32_ref>\n",
      "b3 = <tf.Variable 'b3:0' shape=(25, 1) dtype=float32_ref>\n",
      "W4 = <tf.Variable 'W4:0' shape=(10, 25) dtype=float32_ref>\n",
      "b4 = <tf.Variable 'b4:0' shape=(10, 1) dtype=float32_ref>\n",
      "W5 = <tf.Variable 'W5:0' shape=(5, 10) dtype=float32_ref>\n",
      "b5 = <tf.Variable 'b5:0' shape=(5, 1) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "# Checking the shape of the weights and bias \n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    parameters = initialize_parameters(n_x, n_h)\n",
    "    print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "    print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "    print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "    print(\"b2 = \" + str(parameters[\"b2\"]))\n",
    "    print(\"W3 = \" + str(parameters[\"W3\"]))\n",
    "    print(\"b3 = \" + str(parameters[\"b3\"]))\n",
    "    print(\"W4 = \" + str(parameters[\"W4\"]))\n",
    "    print(\"b4 = \" + str(parameters[\"b4\"]))\n",
    "    print(\"W5 = \" + str(parameters[\"W5\"]))\n",
    "    print(\"b5 = \" + str(parameters[\"b5\"]))\n",
    "    #print(\"W6 = \" + str(parameters[\"W6\"]))\n",
    "    #print(\"b6 = \" + str(parameters[\"b6\"]))\n",
    "    #print(\"W7 = \" + str(parameters[\"W7\"]))\n",
    "    #print(\"b7 = \" + str(parameters[\"b7\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_matrix(labels, C):\n",
    "    \"\"\"\n",
    "    Creates a matrix where the i-th row corresponds to the ith class number and the jth column\n",
    "                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j) \n",
    "                     will be 1. \n",
    "                     \n",
    "    Arguments:\n",
    "    labels -- vector containing the labels \n",
    "    C -- number of classes, the depth of the one hot dimension\n",
    "    \n",
    "    Returns: \n",
    "    one_hot -- one hot matrix\n",
    "    \"\"\"\n",
    "    # Create a tf.constant equal to C (depth), name it 'C'. (approx. 1 line)\n",
    "    C = tf.constant(C, name = \"C\")\n",
    "    \n",
    "    # Use tf.one_hot, be careful with the axis (approx. 1 line)\n",
    "    one_hot_matrix = tf.one_hot(indices = labels, depth = C,axis  =0)\n",
    "    \n",
    "    # Create the session (approx. 1 line)\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # Run the session (approx. 1 line)\n",
    "    one_hot = sess.run(one_hot_matrix)\n",
    "    \n",
    "    # Close the session (approx. 1 line). See method 1 above.\n",
    "    sess.close()\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot = [[ 0.  0.  0.  1.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  1.]\n",
      " [ 0.  1.  0.  0.  1.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Testing one_hot\n",
    "labels = np.array([1,2,3,0,2,1])\n",
    "one_hot = one_hot_matrix(labels, C = 4)\n",
    "print (\"one_hot = \" + str(one_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Y-hat to softmax matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y = \n",
      "[[[ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      " [[ 1.  1.  1. ...,  1.  1.  1.]]\n",
      "\n",
      " [[ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...,  0.  0.  0.]]]\n",
      "trainY-shape = (5, 1, 1893)\n",
      "testY-shape = (5, 1, 470)\n"
     ]
    }
   ],
   "source": [
    "# use one_hot on trainY and testY\n",
    "trainY = one_hot_matrix(trainY, C = 5)\n",
    "testY = one_hot_matrix(testY, C = 5)\n",
    "\n",
    "# bug ? \n",
    "print(\"Y = \")\n",
    "print(trainY)\n",
    "\n",
    "print(\"trainY-shape = \" + str(trainY.shape))\n",
    "print(\"testY-shape = \" + str(testY.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model:\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\", \"W4\", \"b4\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z4 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    W4 = parameters['W4']\n",
    "    b4 = parameters['b4']\n",
    "    W5 = parameters['W5']\n",
    "    b5 = parameters['b5'] \n",
    "    #W6 = parameters['W6']\n",
    "    #b6 = parameters['b6'] \n",
    "    #W7 = parameters['W7']\n",
    "    #b7 = parameters['b7'] \n",
    "    \n",
    "    # Input Layer (Sigmoid)\n",
    "    Z1 = tf.add(tf.matmul(W1,X) , b1)\n",
    "    A1 = tf.nn.tanh(Z1)\n",
    "    \n",
    "    # 1st Hidden Layer (Sigmoid)\n",
    "    Z2 = tf.add(tf.matmul(W2,A1), b2 )  \n",
    "    dropout1 = tf.nn.dropout(Z2, keep_prob = 0.5)\n",
    "    A2 = tf.nn.sigmoid(dropout1)\n",
    "    \n",
    "    # 2nd Hidden Layer (Selu)\n",
    "    Z3 = tf.add(tf.matmul(W3,A2), b3)\n",
    "    dropout2 = tf.nn.dropout(Z3, keep_prob = 0.7)\n",
    "    A3 = tf.nn.selu(dropout2) \n",
    "    \n",
    "    # 3rd Hidden Layer (Selu)\n",
    "    Z4 = tf.add(tf.matmul(W4,A3), b4)    \n",
    "    dropout3 = tf.nn.dropout(Z4, keep_prob = 1)\n",
    "    A4 = tf.nn.selu(dropout3)             \n",
    "    \n",
    "    # Output Layer\n",
    "    Z5 = tf.add(tf.matmul(W5,A4), b5)                                 \n",
    "    #A5 = tf.nn.tanh(Z5)                                              \n",
    "    #Z6 = tf.add(tf.matmul(W6,A5), b6)                                 \n",
    "    #A6 = tf.nn.relu(Z6)                                              \n",
    "    #Z7 = tf.add(tf.matmul(W7,A6), b7)                                \n",
    "    return Z5\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z4 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z4\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    #compute cost\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-48-237d1ee019a2>:18: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "cost = Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(4, 1)\n",
    "    parameters = initialize_parameters(4,1)\n",
    "    Z1 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z1, Y)\n",
    "    print(\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Mini-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "\n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)\n",
    "    mini_batch_size -- size of the mini-batches, integer\n",
    "\n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(seed)            # To make your \"random\" minibatches the same as ours\n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    #permutation = list(np.random.permutation(m))\n",
    "    #shuffled_X = X[:, permutation]\n",
    "    #shuffled_Y = Y[:, 1, permutation]\n",
    "    \n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        mini_batch_X = X[:, k*mini_batch_size : (k+1)*mini_batch_size]\n",
    "        mini_batch_Y = Y[:,:, k*mini_batch_size : (k+1)*mini_batch_size]\n",
    "        ### END CODE HERE ###\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "\n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        mini_batch_X = X[:, num_complete_minibatches*mini_batch_size : m]\n",
    "        mini_batch_Y = Y[:,:, num_complete_minibatches*mini_batch_size : m]\n",
    "        ### END CODE HERE ###\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "\n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the 1st mini_batch_X: (7, 64)\n",
      "shape of the 2nd mini_batch_X: (7, 64)\n",
      "shape of the 3rd mini_batch_X: (7, 64)\n",
      "shape of the last mini_batch_X: (7, 37)\n",
      "shape of the 1st mini_batch_Y: (5, 1, 64)\n",
      "shape of the 2nd mini_batch_Y: (5, 1, 64)\n",
      "shape of the 3rd mini_batch_Y: (5, 1, 64)\n",
      "shape of the last mini_batch_Y: (5, 1, 37)\n"
     ]
    }
   ],
   "source": [
    "mini_batches = random_mini_batches(trainX, trainY, 64, seed=0)\n",
    "\n",
    "print (\"shape of the 1st mini_batch_X: \" + str(mini_batches[0][0].shape))\n",
    "print (\"shape of the 2nd mini_batch_X: \" + str(mini_batches[1][0].shape))\n",
    "print (\"shape of the 3rd mini_batch_X: \" + str(mini_batches[2][0].shape))\n",
    "print (\"shape of the last mini_batch_X: \" + str(mini_batches[-1][0].shape))\n",
    "print (\"shape of the 1st mini_batch_Y: \" + str(mini_batches[0][1].shape))\n",
    "print (\"shape of the 2nd mini_batch_Y: \" + str(mini_batches[1][1].shape)) \n",
    "print (\"shape of the 3rd mini_batch_Y: \" + str(mini_batches[2][1].shape))\n",
    "print (\"shape of the last mini_batch_Y: \" + str(mini_batches[-1][1].shape))\n",
    "#print (\"mini batch sanity check: \")\n",
    "#mini_batches[0][1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(trainX, trainY, testX, testY, learning_rate = 0.0013,\n",
    "          num_epochs = 2200, minibatch_size = 64, print_cost = True, beta = 0.01, beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8):\n",
    "    \"\"\"\n",
    "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    \n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = trainX.shape                                # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = trainY.shape[0]                                  # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "\n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters(n_x, n_h)\n",
    "\n",
    "    # Getting Weights for Regularization \n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    W3 = parameters['W3']\n",
    "    W4 = parameters['W4']\n",
    "    W5 = parameters['W5']\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    Z = forward_propagation(X, parameters)\n",
    "    \n",
    "    # Regularization Term For Cost Function\n",
    "    regularizers = tf.nn.l2_loss(W1) + tf.nn.l2_loss(W2) + tf.nn.l2_loss(W3) + tf.nn.l2_loss(W4) + tf.nn.l2_loss(W5)\n",
    "\n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    cost = compute_cost(Z,Y) + (beta * regularizers)\n",
    "    \n",
    "#     # Cost function: Add cost function to tensorflow graph\n",
    "#     cost = compute_cost(Z,Y)\n",
    "#     print(parameters)\n",
    "\n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate, beta1 = beta1 , beta2 = beta2, epsilon = epsilon ).minimize(cost)\n",
    "\n",
    "#      STACK OVERFLOW\n",
    "#     optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate, beta1 = beta1 , beta2 = beta2, epsilon = epsilon )\n",
    "#     gvs = optimizer.compute_gradients(cost)\n",
    "#     capped_gvs = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gvs]\n",
    "#     train_op = optimizer.apply_gradients(capped_gvs)\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "\n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(trainX, trainY, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "\n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "\n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "\n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: trainX, Y: trainY}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: testX, Y: testY}))\n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Fetch argument <tensorflow.python.training.adam.AdamOptimizer object at 0xb213f8cf8> has invalid type <class 'tensorflow.python.training.adam.AdamOptimizer'>, must be a string or Tensor. (Can not convert a AdamOptimizer into a Tensor or Operation.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    281\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 282\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    283\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3612\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3613\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3701\u001b[0m       raise TypeError(\"Can not convert a %s into a %s.\" % (type(obj).__name__,\n\u001b[0;32m-> 3702\u001b[0;31m                                                            types_str))\n\u001b[0m\u001b[1;32m   3703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can not convert a AdamOptimizer into a Tensor or Operation.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-30f1665d8cae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Testing Adam Optimize with beta1, beta2, epsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-59-699fbd1dadab>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(trainX, trainY, testX, testY, learning_rate, num_epochs, minibatch_size, print_cost, beta, beta1, beta2, epsilon)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0;31m# IMPORTANT: The line that runs the graph on a minibatch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;31m# Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mminibatch_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mminibatch_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mminibatch_Y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0mepoch_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mminibatch_cost\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_minibatches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1120\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \"\"\"\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m       \u001b[0;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_ListFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_DictFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches)\u001b[0m\n\u001b[1;32m    350\u001b[0m     \"\"\"\n\u001b[1;32m    351\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    350\u001b[0m     \"\"\"\n\u001b[1;32m    351\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' % (fetch,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    284\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n\u001b[1;32m    285\u001b[0m                         \u001b[0;34m'must be a string or Tensor. (%s)'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m                         (fetch, type(fetch), str(e)))\n\u001b[0m\u001b[1;32m    287\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[0;31mTypeError\u001b[0m: Fetch argument <tensorflow.python.training.adam.AdamOptimizer object at 0xb213f8cf8> has invalid type <class 'tensorflow.python.training.adam.AdamOptimizer'>, must be a string or Tensor. (Can not convert a AdamOptimizer into a Tensor or Operation.)"
     ]
    }
   ],
   "source": [
    "# Testing Adam Optimize with beta1, beta2, epsilon\n",
    "parameters = model(trainX, trainY, testX,testY, beta = 0.01, beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'beat2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-663cecd1b04c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# beta 0.01 with only reg term\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-52-36c034f362e3>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(trainX, trainY, testX, testY, learning_rate, num_epochs, minibatch_size, print_cost, beta, beta1, beta2, epsilon)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeat2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# Initialize all the variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'beat2' is not defined"
     ]
    }
   ],
   "source": [
    "# beta 0.01 with only reg term \n",
    "parameters = model(trainX, trainY, testX,testY, beta = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.269552\n",
      "Cost after epoch 100: 0.438901\n",
      "Cost after epoch 200: 0.431193\n",
      "Cost after epoch 300: 0.428889\n",
      "Cost after epoch 400: 0.427879\n",
      "Cost after epoch 500: 0.427350\n",
      "Cost after epoch 600: 0.427041\n",
      "Cost after epoch 700: 0.426856\n",
      "Cost after epoch 800: 0.426739\n",
      "Cost after epoch 900: 0.426653\n",
      "Cost after epoch 1000: 0.426590\n",
      "Cost after epoch 1100: 0.426545\n",
      "Cost after epoch 1200: 0.426508\n",
      "Cost after epoch 1300: 0.426476\n",
      "Cost after epoch 1400: 0.426446\n",
      "Cost after epoch 1500: 0.426416\n",
      "Cost after epoch 1600: 0.426381\n",
      "Cost after epoch 1700: 0.426339\n",
      "Cost after epoch 1800: 0.426285\n",
      "Cost after epoch 1900: 0.426209\n",
      "Cost after epoch 2000: 0.426122\n",
      "Cost after epoch 2100: 0.426056\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy: 0.913365\n",
      "Test Accuracy: 0.910638\n"
     ]
    }
   ],
   "source": [
    "# beta 0.02 with only reg term \n",
    "parameters = model(trainX, trainY, testX,testY, beta = 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.572870\n",
      "Cost after epoch 100: 0.438955\n",
      "Cost after epoch 200: 0.430509\n",
      "Cost after epoch 300: 0.428240\n",
      "Cost after epoch 400: 0.427377\n",
      "Cost after epoch 500: 0.426973\n",
      "Cost after epoch 600: 0.426761\n",
      "Cost after epoch 700: 0.426644\n",
      "Cost after epoch 800: 0.426567\n",
      "Cost after epoch 900: 0.426508\n",
      "Cost after epoch 1000: 0.426455\n",
      "Cost after epoch 1100: 0.426406\n",
      "Cost after epoch 1200: 0.426356\n",
      "Cost after epoch 1300: 0.426285\n",
      "Cost after epoch 1400: 0.426180\n",
      "Cost after epoch 1500: 0.426084\n",
      "Cost after epoch 1600: 0.426054\n",
      "Cost after epoch 1700: 0.426055\n",
      "Cost after epoch 1800: 0.426054\n",
      "Cost after epoch 1900: 0.426054\n",
      "Cost after epoch 2000: 0.426055\n",
      "Cost after epoch 2100: 0.426056\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy: 0.913365\n",
      "Test Accuracy: 0.910638\n"
     ]
    }
   ],
   "source": [
    "# beta 0.03 with only reg term \n",
    "parameters = model(trainX, trainY, testX,testY, beta = 0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 2.173413\n",
      "Cost after epoch 100: 0.438185\n",
      "Cost after epoch 200: 0.429141\n",
      "Cost after epoch 300: 0.427324\n",
      "Cost after epoch 400: 0.426782\n",
      "Cost after epoch 500: 0.426570\n",
      "Cost after epoch 600: 0.426464\n",
      "Cost after epoch 700: 0.426395\n",
      "Cost after epoch 800: 0.426309\n",
      "Cost after epoch 900: 0.426179\n",
      "Cost after epoch 1000: 0.426066\n",
      "Cost after epoch 1100: 0.426066\n",
      "Cost after epoch 1200: 0.426058\n",
      "Cost after epoch 1300: 0.426054\n",
      "Cost after epoch 1400: 0.426060\n",
      "Cost after epoch 1500: 0.426055\n",
      "Cost after epoch 1600: 0.426054\n",
      "Cost after epoch 1700: 0.426054\n",
      "Cost after epoch 1800: 0.426061\n",
      "Cost after epoch 1900: 0.426054\n",
      "Cost after epoch 2000: 0.426054\n",
      "Cost after epoch 2100: 0.426054\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy: 0.913365\n",
      "Test Accuracy: 0.910638\n"
     ]
    }
   ],
   "source": [
    "# beta 0.05 with only reg term \n",
    "parameters = model(trainX, trainY, testX,testY, beta = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Dropout  With beta = 0.01\n",
    "parameters = model(trainX, trainY, testX,testY, beta = 0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
