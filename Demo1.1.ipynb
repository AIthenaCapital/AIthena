{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the package working or not\n",
    "###  - test tensorflow and pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date  Price        RSI  Stedev from 20 MA  MACD n.f  50MA_N.F.  \\\n",
      "0 2011-12-16   3.25  51.415094           0.591527  1.594689   0.500194   \n",
      "1 2011-12-18   3.25  44.324324           0.516482  1.489778   0.571086   \n",
      "2 2011-12-19   3.50  51.196172           1.311777  1.473728   1.266368   \n",
      "3 2011-12-20   4.75  82.269504           3.461711  1.840524   3.831441   \n",
      "4 2011-12-21   4.38  75.324675           2.180044  1.969366   2.760808   \n",
      "\n",
      "   actions  y-hat  Unnamed: 8   Unnamed: 9  \n",
      "0      NaN      2           1  2157.000000  \n",
      "1      NaN      2           1     0.912437  \n",
      "2      NaN      2           1          NaN  \n",
      "3      NaN      2           1          NaN  \n",
      "4      NaN      2           1          NaN  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('BTC daily_database.xlsx', sheet_name=3)\n",
    "# testing the input is correct or not\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(0,dtype=tf.float32)\n",
    "cost = tf.add(tf.add(w**2,tf.multiply(-10.,w)),25)\n",
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print(sess.run(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.099999994\n"
     ]
    }
   ],
   "source": [
    "sess.run(train)\n",
    "print(sess.run(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.9999886\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    sess.run(train)\n",
    "print(sess.run(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4, 2363)\n",
      "number of training samples = 2363\n",
      "number of variables = 4\n",
      "[[51.41509434 44.32432432 51.19617225 ... 41.54757836 54.30118701\n",
      "  52.88985174]\n",
      " [ 0.59152723  0.51648236  1.31177743 ... -0.22095621 -0.06774514\n",
      "   0.05516699]\n",
      " [ 1.59468902  1.48977812  1.47372773 ... -0.43278934 -0.33627381\n",
      "  -0.24796018]\n",
      " [ 0.50019378  0.57108639  1.26636805 ... -1.09502132 -1.03113801\n",
      "  -0.98767088]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\john liu\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\john liu\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "inputX = df.iloc[:,2:6 ].as_matrix()\n",
    "inputX = inputX.T\n",
    "inputY = df.iloc[:, 7:8].as_matrix()\n",
    "inputY = inputY.T\n",
    "print(\"X_train shape: \" + str(inputX.shape))\n",
    "print(\"number of training samples = \"+ str(inputX.shape[1]))\n",
    "print(\"number of variables = \" + str(inputX.shape[0]))\n",
    "print(inputX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 2, ..., 2, 2, 2]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## layer size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_x's shape = 4\n",
      "first layer(n_h)'s shape = 5\n",
      "n_y's output = 1\n"
     ]
    }
   ],
   "source": [
    "n_x = inputX.shape[0] # size of input layer\n",
    "n_h = 5\n",
    "n_y = inputY.shape[0]\n",
    "print(\"n_x's shape = \" + str(n_x))\n",
    "print(\"first layer(n_h)'s shape = \" + str(n_h))\n",
    "print(\"n_y's output = \" + str(n_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create placeholder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    \n",
    "    #Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, shape = [n_x,None])\n",
    "    Y = tf.placeholder(tf.float32, shape = [n_y, None])  \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"Placeholder:0\", shape=(4, ?), dtype=float32)\n",
      "(4, ?)\n",
      "Y = Tensor(\"Placeholder_1:0\", shape=(1, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X, Y = create_placeholders(n_x,n_y)\n",
    "print (\"X = \" + str(X))\n",
    "print(X.shape)\n",
    "print (\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def initialize_parameters(n_x, n_h):\n",
    "    #Initializes weight parameters to build a neural network with tensorflow  \n",
    "    #tf.set_random_seed()                              \n",
    "    W1 = tf.get_variable(\"W1\", [n_h,n_x], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    b1 = tf.get_variable(\"b1\", [n_h,1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [5, n_h], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    b2 = tf.get_variable(\"b2\", [5,1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [5, 5], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    b3 = tf.get_variable(\"b3\", [5,1], initializer = tf.zeros_initializer())\n",
    "    W4 = tf.get_variable(\"W4\", [5, 5], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    b4 = tf.get_variable(\"b4\", [5,1], initializer = tf.zeros_initializer())\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3,\n",
    "                  \"W4\": W4,\n",
    "                  \"b4\": b4}\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = <tf.Variable 'W1:0' shape=(5, 4) dtype=float32_ref>\n",
      "b1 = <tf.Variable 'b1:0' shape=(5, 1) dtype=float32_ref>\n",
      "W2 = <tf.Variable 'W2:0' shape=(5, 5) dtype=float32_ref>\n",
      "b2 = <tf.Variable 'b2:0' shape=(5, 1) dtype=float32_ref>\n",
      "W3 = <tf.Variable 'W3:0' shape=(5, 5) dtype=float32_ref>\n",
      "b3 = <tf.Variable 'b3:0' shape=(5, 1) dtype=float32_ref>\n",
      "W4 = <tf.Variable 'W4:0' shape=(5, 5) dtype=float32_ref>\n",
      "b4 = <tf.Variable 'b4:0' shape=(5, 1) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    parameters = initialize_parameters(n_x, n_h)\n",
    "    print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "    print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "    print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "    print(\"b2 = \" + str(parameters[\"b2\"]))\n",
    "    print(\"W3 = \" + str(parameters[\"W3\"]))\n",
    "    print(\"b3 = \" + str(parameters[\"b3\"]))\n",
    "    print(\"W4 = \" + str(parameters[\"W4\"]))\n",
    "    print(\"b4 = \" + str(parameters[\"b4\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_matrix(labels, C):\n",
    "    \"\"\"\n",
    "    Creates a matrix where the i-th row corresponds to the ith class number and the jth column\n",
    "                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j) \n",
    "                     will be 1. \n",
    "                     \n",
    "    Arguments:\n",
    "    labels -- vector containing the labels \n",
    "    C -- number of classes, the depth of the one hot dimension\n",
    "    \n",
    "    Returns: \n",
    "    one_hot -- one hot matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a tf.constant equal to C (depth), name it 'C'. (approx. 1 line)\n",
    "    C = tf.constant(C, name = \"C\")\n",
    "    \n",
    "    # Use tf.one_hot, be careful with the axis (approx. 1 line)\n",
    "    one_hot_matrix = tf.one_hot(indices = labels, depth = C,axis  =0)\n",
    "    \n",
    "    # Create the session (approx. 1 line)\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # Run the session (approx. 1 line)\n",
    "    one_hot = sess.run(one_hot_matrix)\n",
    "    \n",
    "    # Close the session (approx. 1 line). See method 1 above.\n",
    "    sess.close()\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot = [[0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "labels = np.array([1,2,3,0,2,1])\n",
    "one_hot = one_hot_matrix(labels, C = 4)\n",
    "print (\"one_hot = \" + str(one_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Y-hat to softmax matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y = \n",
      "[[[0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[1. 1. 1. ... 1. 1. 1.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]]]\n",
      "Y-shape = (5, 1, 2363)\n"
     ]
    }
   ],
   "source": [
    "Y = one_hot_matrix(inputY, C = 5)\n",
    "print(\"Y = \")\n",
    "print(Y)\n",
    "print(\"Y-shape = \" + str(Y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> Sigmoid -> LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\", \"W4\", \"b4\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z4 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    W4 = parameters['W4']\n",
    "    b4 = parameters['b4']\n",
    "    \n",
    "                                                                     # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1,X) , b1 )                               # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.sigmoid(Z1)                                           # A1 = sigmoid(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2,A1), b2 )                               # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                              # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3,A2), b3)                                # Z3 = np.dot(W3,Z2) + b3\n",
    "    A3 = tf.nn.relu(Z3)                                              # A3 = relu(Z2)\n",
    "    Z4 = tf.add(tf.matmul(W4,A3), b4)                                # Z4 = np.dot(W3,Z2) + b3 \n",
    "    \n",
    "    return Z4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z4, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z4 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z4\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z4)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    #compute cost\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-17-10e815154d16>:18: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "cost = Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(4, 5)\n",
    "    parameters = initialize_parameters(4,5)\n",
    "    Z4 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z4, Y)\n",
    "    print(\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "\n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)\n",
    "    mini_batch_size -- size of the mini-batches, integer\n",
    "\n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(seed)            # To make your \"random\" minibatches the same as ours\n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    '''\n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X.values[:, permutation]\n",
    "    shuffled_Y = Y.values[:, permutation].reshape((1,m))\n",
    "    '''\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        mini_batch_X = X[:, k*mini_batch_size : (k+1)*mini_batch_size]\n",
    "        mini_batch_Y = Y[:, k*mini_batch_size : (k+1)*mini_batch_size]\n",
    "        ### END CODE HERE ###\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "\n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        mini_batch_X = X[:, num_complete_minibatches*mini_batch_size : m]\n",
    "        mini_batch_Y = Y[:, num_complete_minibatches*mini_batch_size : m]\n",
    "        ### END CODE HERE ###\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "\n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2363, 2363)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test(X,Y):\n",
    "    m = X.shape[1]\n",
    "    n = Y.shape[1]\n",
    "    return m, n\n",
    "test(inputX,inputY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the 1st mini_batch_X: (4, 32)\n",
      "shape of the 2nd mini_batch_X: (4, 32)\n",
      "shape of the 3rd mini_batch_X: (4, 32)\n",
      "shape of the last mini_batch_X: (4, 27)\n",
      "shape of the 1st mini_batch_Y: (1, 32)\n",
      "shape of the 2nd mini_batch_Y: (1, 32)\n",
      "shape of the 3rd mini_batch_Y: (1, 32)\n",
      "shape of the last mini_batch_Y: (1, 27)\n",
      "mini batch sanity check: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([51.41509434, 44.32432432, 51.19617225, 82.26950355, 75.32467532,\n",
       "       70.21943574, 62.01780415, 64.64088398, 65.73033708, 65.36312849,\n",
       "       63.95348837, 65.47619048, 63.75      , 63.55140187, 67.8125    ,\n",
       "       69.61651917, 71.06741573, 60.8365019 , 60.37735849, 73.53846154,\n",
       "       86.23376623, 84.98583569, 85.63535912, 87.15846995, 71.95402299,\n",
       "       77.3512476 , 74.5825603 , 73.09090909, 68.60670194, 70.96247961,\n",
       "       59.00900901, 58.88554217])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_batches = random_mini_batches(inputX, inputY, 32, seed=0)\n",
    "\n",
    "print (\"shape of the 1st mini_batch_X: \" + str(mini_batches[0][0].shape))\n",
    "print (\"shape of the 2nd mini_batch_X: \" + str(mini_batches[1][0].shape))\n",
    "print (\"shape of the 3rd mini_batch_X: \" + str(mini_batches[2][0].shape))\n",
    "print (\"shape of the last mini_batch_X: \" + str(mini_batches[-1][0].shape))\n",
    "print (\"shape of the 1st mini_batch_Y: \" + str(mini_batches[0][1].shape))\n",
    "print (\"shape of the 2nd mini_batch_Y: \" + str(mini_batches[1][1].shape)) \n",
    "print (\"shape of the 3rd mini_batch_Y: \" + str(mini_batches[2][1].shape))\n",
    "print (\"shape of the last mini_batch_Y: \" + str(mini_batches[-1][1].shape))\n",
    "print (\"mini batch sanity check: \")\n",
    "mini_batches[0][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  â†‘\n",
    "### something is wrong with the minibatch on above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(inputX, inputY, learning_rate = 0.0001,\n",
    "          num_epochs = 1500, minibatch_size = 32, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    \n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = inputX.shape                           # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = inputY.shape[0]                             # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "\n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters(n_x, n_h)\n",
    "\n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    Z4 = forward_propagation(X, parameters)\n",
    "\n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    cost = compute_cost(Z4, Y)\n",
    "\n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "\n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "\n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(inputX, inputY, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "\n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "\n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "\n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z4), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: inputX, Y: inputY}))\n",
    "\n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 21.435783\n",
      "Cost after epoch 100: 261.813605\n",
      "Cost after epoch 200: 703.336733\n",
      "Cost after epoch 300: 1455.300231\n",
      "Cost after epoch 400: 2330.639232\n",
      "Cost after epoch 500: 3372.458824\n",
      "Cost after epoch 600: 4568.928942\n",
      "Cost after epoch 700: 5909.180223\n",
      "Cost after epoch 800: 7382.785772\n",
      "Cost after epoch 900: 8979.442196\n",
      "Cost after epoch 1000: 10688.042093\n",
      "Cost after epoch 1100: 12507.708516\n",
      "Cost after epoch 1200: 14423.604452\n",
      "Cost after epoch 1300: 16401.163835\n",
      "Cost after epoch 1400: 18617.424082\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8FeXZ//HPRdj3fSeyCCogAgZwq2K1iEuLWrVaF1QsSrWP2tVWrbZqf1qrffRxqwsCrlisFXGl1l1Zguyb7BDDEggkgRDIcv3+OBN7GrMBJ5lzTr7v1+u8zpx77pm57kxyrsw9M/eYuyMiIhIL9cIOQEREkoeSioiIxIySioiIxIySioiIxIySioiIxIySioiIxIySighgZm+b2diw4xBJdEoqEiozW29mp4cdh7uf6e6Tw44DwMw+NLNramE7jcxsopnlmtkWM/t5FfVvDurlBMs1iprX08w+MLN8M1tRdp9WsexdZrbYzIrM7M6YN1RqlZKKJD0zqx92DKXiKRbgTqAvcBhwKvBrMxtdXkUzOwO4BTgN6An0Bv4QVeUlYD7QDrgVmGZmHaq57Grg18CbMWmVhEpJReKWmZ1jZgvMbJeZfW5mg6Lm3WJma8wsz8yWmdl5UfOuNLPPzOyvZpYN3BmUfWpmfzGznWa2zszOjFrmm6ODatTtZWYfB9v+l5k9ambPV9CGkWaWYWa/MbMtwLNm1sbMZphZVrD+GWbWPah/D/Ad4BEz221mjwTlR5rZTDPLNrOVZnZRDH7EVwB3uftOd18OPAVcWUHdscAz7r7U3XcCd5XWNbN+wFDgDnff6+6vAouBH1a1LIC7T3b3t4G8GLRJQqakInHJzIYCE4Frifz3+zdgelS3yRoiX76tiPzX+7yZdYlaxQhgLdARuCeqbCXQHvgz8IyZWQUhVFb3RWBOENedwOVVNKcz0JbIEcF4In93zwafU4G9wCMA7n4r8Alwg7s3d/cbzKwZMDPYbkfgEuAxMxtQ3sbM7LEgEZf3WhTUaQN0BRZGLboQKHedQXnZup3MrF0wb62755WZP6Aay0qSUVKRePUT4G/uPtvdi4PzHfuA4wDc/e/ununuJe4+FVgFDI9aPtPd/8/di9x9b1C2wd2fcvdiYDLQBehUwfbLrWtmqcAw4Pfuvt/dPwWmV9GWEiL/xe8L/pPf4e6vunt+8EV8D3BKJcufA6x392eD9nwJvApcUF5ld/+pu7eu4FV6tNc8eM+JWjQHaFFBDM3LqUtQv+y8suuqbFlJMkoqEq8OA34R/V820IPIf9eY2RVRXWO7gIFEjipKbSpnnVtKJ9w9P5hsXk69yup2BbKjyiraVrQsdy8o/WBmTc3sb2a2wcxygY+B1maWUsHyhwEjyvwsLiVyBHSwdgfvLaPKWlJxF9TucuoS1C87r+y6KltWkoySisSrTcA9Zf7LburuL5nZYUT6/28A2rl7a2AJEN2VVVPDb28G2ppZ06iyHlUsUzaWXwBHACPcvSVwclBuFdTfBHxU5mfR3N0nlLcxM3siOB9T3mspQHBuYzNwTNSixwBLK2jD0nLqbnX3HcG83mbWosz8pdVYVpKMkorEgwZm1jjqVZ9I0rjOzEZYRDMzOzv44mpG5Is3C8DMriJypFLj3H0DkE7k5H9DMzse+P4BrqYFkfMou8ysLXBHmflbiVwhVWoG0M/MLjezBsFrmJkdVUGM1wVJp7xX9DmTKcBtwYUDRxLpcpxUQcxTgHFm1j84H3NbaV13/wpYANwR7L/zgEFEuugqXRYgaE9jIt9H9YN1VHTUJnFOSUXiwVtEvmRLX3e6ezqRL7lHgJ1ELju9EsDdlwEPAF8Q+QI+GvisFuO9FDge2AHcDUwlcr6nuv4XaAJsB2YB75SZ/xBwQXBl2MPBeZdRwMVAJpGuufuARhyaO4hc8LAB+Ai4393fATCz1ODIJhUgKP8z8EFQfwP/nQwvBtKI7Kt7gQvcPauayz5FZL9fQuRy5L1UffGDxCnTQ7pEDo2ZTQVWuHvZIw6ROkdHKiIHKOh66mNm9Sxys+AY4J9hxyUSD+Lp7l6RRNEZ+AeR+1QygAnuPj/ckETig7q/REQkZtT9JSIiMVPnur/at2/vPXv2DDsMEZGEMm/evO3u3qGqenUuqfTs2ZP09PSwwxARSShmtqE69dT9JSIiMaOkIiIiMaOkIiIiMaOkIiIiMaOkIiIiMaOkIiIiMaOkIiIiMaOkIiKS5NZm7eb+d1dQXFLzw3IpqYiIJLHtu/dx5bNzeWnOJrblFVS9wCFSUhERSVJ79xdzzeR0tuUV8MzYNLq0alLj26xzw7SIiNQFxSXOjS/PZ2HGLp647FiGpLaple3qSEVEJAnd/eYy3lu2ld+f058zBnSute0qqYiIJJlnPl3Hs5+tZ9xJvbjqxF61um0lFRGRJPL24s3c/eYyzhzYmVvPOqrWt19jScXMepjZB2a23MyWmtmNQXlbM5tpZquC9zZBuZnZw2a22swWmdnQqHWNDeqvMrOxUeXHmtniYJmHzcxqqj0iIvFu3oZsbpq6gCE9WvPXHw2mXr3a/0qsySOVIuAX7n4UcBxwvZn1B24B3nf3vsD7wWeAM4G+wWs88DhEkhBwBzACGA7cUZqIgjrjo5YbXYPtERGJW+u27+Gayel0adWYp8cOo3GDlFDiqLGk4u6b3f3LYDoPWA50A8YAk4Nqk4Fzg+kxwBSPmAW0NrMuwBnATHfPdvedwExgdDCvpbt/4e4OTIlal4hInbFj9z6uenYOZsakq4bTtlnD0GKplXMqZtYTGALMBjq5+2aIJB6gY1CtG7AparGMoKyy8oxyysvb/ngzSzez9KysrENtjohI3CgoLOaaKelszing6bFp9GzfLNR4ajypmFlz4FXgJnfPraxqOWV+EOXfLnR/0t3T3D2tQ4cqH7EsIpIQSu9FWbBpFw9dPIShtXQvSmVqNKmYWQMiCeUFd/9HULw16LoieN8WlGcAPaIW7w5kVlHevZxyEZGk5+7c/voS3l26lTvO6c/ogbV3L0plavLqLwOeAZa7+4NRs6YDpVdwjQVejyq/IrgK7DggJ+geexcYZWZtghP0o4B3g3l5ZnZcsK0rotYlIpLUHn5/NS/O3shPR/bhylq+F6UyNTlMy4nA5cBiM1sQlP0OuBd4xczGARuBC4N5bwFnAauBfOAqAHfPNrO7gLlBvT+6e3YwPQGYBDQB3g5eIiJJ7cXZG/nrv77igmO786szjgg7nP9ikQun6o60tDRPT08POwwRkYPy7tItTHh+Hqf068CTV6TRIKV27mE3s3nunlZVPd1RLyKSIOauz+Z/XprPoO6tefTSobWWUA5E/EUkIiLf8tXWPMZNmku31k2YeOUwmjaMz0HmlVREROJc5q69jJ04h8YNUph8dbg3N1ZFSUVEJI7tyt/PFRPnsLugiElXDadH26Zhh1Sp+Dx+EhGRyN3yk9PZuCOfyVcPp3/XlmGHVCUlFRGROFRUXMINL85n3sadPHLJUI7v0y7skKpF3V8iInHG3bntn0v41/Kt3Pn9AZw9qEvYIVWbkoqISJy5752VvDx3E9ef2oexJ/QMO5wDoqQiIhJHnvhoDU98tIYfj0jll6Pi62756lBSERGJEy/N2ci9b6/gnEFduGvMQBLxYbZKKiIiceCtxZu59bXFnNKvAw9eNJiUEB4FHAtKKiIiIftkVRY3vjyfIalteOKyY2lYP3G/mhM3chGRJDBvw07GT5lHnw7NmTh2GE0ahvNs+VhRUhERCcnKLXlcPWkuHVs2Ysq44bRq2iDskA6ZkoqISAg27sjn8mdm06h+PZ4fN4KOLRqHHVJM6I56EZFati23gMuemc3+4hJeufb4uB/P60DoSEVEpBbl5Bdy+TNz2L57H89eOYx+nVqEHVJMKamIiNSSPfuKuGrSHNZt38OTl6cxJLVN2CHFnJKKiEgtKCgs5idT0lmwaRcPXTyYk/q2DzukGqFzKiIiNWx/UQk/feFLvli7gwcuPIYzj06cASIPlI5URERqUFFxCTdNnc+/V2zj7nMHcv7Q7mGHVKOUVEREakhxifPrVxfx1uIt3Hb2UVw64rCwQ6px6v4SEakB+4tKuPmVBby5aDM//14/rvlO77BDqhVKKiIiMbZ3fzETXpjHhyuz+N1ZRzL+5D5hh1RrlFRERGIot6CQcZPmkr5hJ/eefzQXD08NO6RapaQiIhIj23fvY+zEOXy1NY9HLhmaUI8BjhUlFRGRGPh6114uf3o2mTl7eeqKNEYe0THskEKhpCIicojWZu3msqdnk7eviOfGjWBYz7ZhhxQaJRURkUOw5Oscxk6cA8DL449jQNdWIUcULiUVEZGDNHd9Nlc/O5cWjevz/DUj6N2hedghhU5JRUTkIHy4chvXPT+Prq2b8Py4EXRt3STskOKCkoqIyAGasSiTm6cuoF+nFky+ejjtmzcKO6S4oaQiInIAXpy9kVv/uZi0w9rwzJXDaNk48R8BHEtKKiIi1eDuPPrBav7y3lecekQHHrv0WJo0TAk7rLijpCIiUoWSEuePM5Yx6fP1nD+kG/ddMIgGKRqPtzxKKiIilSgsLuFXf1/IPxdkMu6kXtx61lHUq2dhhxW3lFRERCqQv7+In77wJR+uzOLXo49gwil9MFNCqYySiohIOXbl7+fqSXNZsGlXnRwY8mDVWKegmU00s21mtiSq7E4z+9rMFgSvs6Lm/dbMVpvZSjM7I6p8dFC22sxuiSrvZWazzWyVmU01s4Y11RYRqVs25+zlwie+YMnXuTx26VAllANQk2eaJgGjyyn/q7sPDl5vAZhZf+BiYECwzGNmlmJmKcCjwJlAf+CSoC7AfcG6+gI7gXE12BYRqSPWZO3mgse/YHNOAZOuHsbogXVvpOFDUWNJxd0/BrKrWX0M8LK773P3dcBqYHjwWu3ua919P/AyMMYinZrfBaYFy08Gzo1pA0SkzlmUsYsLn/iCgsJiXh5/HCf0aR92SAknjGvibjCzRUH3WJugrBuwKapORlBWUXk7YJe7F5UpL5eZjTezdDNLz8rKilU7RCSJfLpqO5c8OYumDVOYNuEEBnar2wNDHqzaTiqPA32AwcBm4IGgvLzLKfwgysvl7k+6e5q7p3Xo0OHAIhaRpPfmos1cPWku3ds05dUJJ9CrfbOwQ0pYtXr1l7tvLZ02s6eAGcHHDKBHVNXuQGYwXV75dqC1mdUPjlai64uIVNvzszZw++tLODa1Dc+MHUarphp25VDU6pGKmUWf8ToPKL0ybDpwsZk1MrNeQF9gDjAX6Btc6dWQyMn86e7uwAfABcHyY4HXa6MNIpIc3J2H31/Fbf9cwqlHdOS5cSOUUGKgxo5UzOwlYCTQ3swygDuAkWY2mEhX1XrgWgB3X2pmrwDLgCLgencvDtZzA/AukAJMdPelwSZ+A7xsZncD84FnaqotIpJcikucP76xlMlfbNCwKzFmkX/66460tDRPT08POwwRCUlBYTE3vbyAd5Zu4Sff6cVvz9SwK9VhZvPcPa2qerqjXkTqjJz8Qn4yJZ0567O57eyjuOY7vcMOKekoqYhInfD1rr1cOXEOG3bk83+XDOH7x3QNO6SkpKQiIklvxZZcrpw4lz37iph09TDd1FiDlFREJKl9sWYH46ek07RRCq9cdzxHdWkZdkhJTUlFRJLWjEWZ/HzqQlLbNWXy1cPp1rpJ2CElPSUVEUlKEz9dx11vLuPY1DY8PTaN1k01kHltUFIRkaRSUuLc+84Knvx4LaMHdOZ/Lx5M4wZ6lnxtUVIRkaSxv6iEX01byOsLMrni+MO44/sDSNE9KLVKSUVEkkJeQSHXPT+Pz1bv4FdnHMFPR+rRv2FQUhGRhLctt4Cxz85l1dY8/nLhMVxwbPewQ6qzlFREJKGt3rabsRPnsDN/P0+PTWPkER3DDqlOU1IRkYQ1b0M24yanU7+eMXX88RzdXQ/WCpuSiogkpJnLtnLDi1/SpVVjplw9gtR2TcMOSVBSEZEE9MLsDdz+zyUc3a0VE68cRrvmjcIOSQJKKiKSMNydB2d+xf/9ezWnHtGBRy8dStOG+hqLJ9obIpIQ9hUVc8uri3lt/tf8KK0H95w3kPp6sFbcUVIRkbiXk1/I+OfSmb0um1+O6sf1px6ue1DilJKKiMS1jTvyuXLSHDKy9/LQxYMZM7hb2CFJJZRURCRuzd+4k2smp1NU4jw3bjgjercLOySpgpKKiMSltxdv5qapC+jUsjHPXjWMPh2ahx2SVIOSiojEFXfnmU/Xcc9byxncozVPX5GmS4YTiJKKiMSNouIS/vDGMp6btYEzB3bmrz/SsPWJRklFROLCnn1F/Oyl+fx7xTauPbk3vxl9JPU0bH3CUVIRkdBtzS3g6klzWb45l7vOHcjlxx0WdkhykJRURCRUSzNzuGZyOjl7C3lm7DBOPVKjDCcyJRURCc17S7dw09QFtGzcgFeuPZ6B3TTKcKJTUhGRWufu/O3jtdz3zgoGdWvFU1ek0bFl47DDkhhQUhGRWrWvqJhbX1vCtHkZnDOoC3+58Bhd4ZVElFREpNbs2L2P656fx9z1O7nxtL7cdHpfjeGVZKo1xKeZXVidMhGRiny1NY9zH/uMRRk5PHzJEG7+Xj8llCRU3XGjf1vNMhGRb/lg5TbOf+xzCgpLmHrt8fzgmK5hhyQ1pNLuLzM7EzgL6GZmD0fNagkU1WRgIpL43J1nP1vP3W8u48jOLXl6bBpdWzcJOyypQVWdU8kE0oEfAPOiyvOAm2sqKBFJfIXFJdwxfSkvzt7IqP6d+N+LB+spjXVApXvY3RcCC83sRXcvBDCzNkAPd99ZGwGKSOLZsXsfE174kjnrspkwsg+/GnWEhlypI6r7b8NMM/tBUH8BkGVmH7n7z2suNBFJREszcxg/ZR7bd+/TQ7XqoOqeqG/l7rnA+cCz7n4scHrNhSUiieiNhZn88PHPKXFn2nUnKKHUQdU9UqlvZl2Ai4BbazAeEUlAxSXOA++t5LEP15B2WBsev+xYOrTQM1DqouomlT8C7wKfuftcM+sNrKq5sEQkUeQWFHLjS/P5YGUWlwxP5Q8/GEDD+tXtBJFkU6097+5/d/dB7j4h+LzW3X9Y2TJmNtHMtpnZkqiytmY208xWBe9tgnIzs4fNbLWZLTKzoVHLjA3qrzKzsVHlx5rZ4mCZh013UYnUujVZuzn30c/4ZNV27j53IP/v/KOVUOq46t5R393MXguSxFYze9XMulex2CRgdJmyW4D33b0v8H7wGeBMoG/wGg88Hmy3LXAHMAIYDtxRmoiCOuOjliu7LRGpQR+s2Ma5j3xGTn4hL1wzgsv0DBSh+ifqnwWmA12BbsAbQVmF3P1jILtM8RhgcjA9GTg3qnyKR8wCWgfncM4AZrp7dnAJ80xgdDCvpbt/4e4OTIlal4jUIHfnsQ9Xc/XkufRo25TXbziREb3bhR2WxInqnlPp4O7RSWSSmd10ENvr5O6bAdx9s5mVPo2nG7Apql5GUFZZeUY55SJSg3bvK+I30xbx5uLNnDOoC/dfcAxNGmqEYfmP6iaV7WZ2GfBS8PkSYEcM4yjvfIgfRHn5KzcbT6SrjNTU1IOJT6TOW5O1m2ufm8farN3ccuaRXHtybw0IKd9S3e6vq4lcTrwF2AxcAFx1ENvbGnRdEbxvC8ozgB5R9boTGSKmsvLu5ZSXy92fdPc0d0/r0KHDQYQtUre9s2QLYx75jOw9+3l+3AiuO6WPEoqUq7pJ5S5grLt3cPeORJLMnQexvelA6RVcY4HXo8qvCK4COw7ICbrJ3gVGmVmb4AT9KODdYF6emR0XXPV1RdS6RCRGikuc+95ZwXXPz6NPx+bM+NlJnHB4+7DDkjhW3e6vQdFjfbl7tpkNqWwBM3sJGAm0N7MMIldx3Qu8YmbjgI1A6TNZ3iIyGvJqIJ/gKCjYzl3A3KDeH9299OT/BCJXmDUB3g5eIhIj2Xv28z8vzefT1dv58YhU7vh+fxrV1/kTqVx1k0o9M2tTmliCS32rGozykgpmnVZOXQeur2A9E4GJ5ZSnAwOriFtEDsKijF1MeP5Lsnbv488XDOKitB5VLyRC9ZPKA8DnZjaNyAnxi4B7aiwqEQnN1Lkbuf31pXRo3ohXrzuBo7u3CjskSSDVSiruPsXM0oHvErny6nx3X1ajkYlIrSooLObO6Ut5ee4mvtO3PQ9dPIS2zRqGHZYkmGo/MSdIIkokIkno6117mfD8PBZl5HD9qX34+feOIEXPP5GDoMewidRxH6zYxs2vLKCo2Hny8mMZNaBz2CFJAlNSEamjiopLeGDmVzz+4RqO6tKSxy4dSq/2zcIOSxKckopIHbQ1t4CfvTSfOeuyuWR45HLhxg10ubAcOiUVkTrmk1VZ3PTyAvYWFvO/PxrMuUM0bJ7EjpKKSB1RXOI8/P4qHv73Kvp2bM5jlw7l8I4twg5LkoySikgdkJW3j5umzuez1Tv44dDu3HXuAJo21J+/xJ5+q0SS3Ky1O/jZS/PJ3Vuou+OlximpiCSpkhLn8Y/W8MB7K+nZvhnPjRvOkZ1bhh2WJDklFZEklJW3j1/+fSEffZXFD47pyp/OP5rmjfTnLjVPv2UiSeaTVVncPHUhuQWF3H3uQC4dkapnn0itUVIRSRKFxSU88N5X/O3jNRzeoTnPX6PuLql9SioiSWBTdj4/e2k+Czbt4pLhqfz+nP56dryEQklFJMG9sTCT3/1jMRg8+uOhnD2oS9ghSR2mpCKSoPL3F/GH6cuYmr6JoamteejiIfRo2zTssKSOU1IRSUDLN+dyw4tfsnb7Hq4/tQ83nd6PBin1wg5LRElFJJGUlDgTP1vHn99ZSaumDXh+3AhOPLx92GGJfENJRSRBbM7Zyy9eWcjna3Zw+lGduPeHR9O+eaOwwxL5L0oqIglgxqLIyfjCYufe84/mR8N66N4TiUtKKiJxLLegkDteX8pr879mcI/W/PVHg/UgLYlrSioicWr22h38/JWFbMkt4KbT+3LDqYdTXyfjJc4pqYjEmf1FJTw4M3Jn/GFtmzLtuuMZktom7LBEqkVJRSSOrNqax01TF7A0M5dLhvfgtrP700wDQUoC0W+rSBwoLnGe/Wwd97+7kmaN6vPk5ccyakDnsMMSOWBKKiIhW799D7+atpC563dy+lEd+dP5R9OxReOwwxI5KEoqIiEpKXGmfLGee99ZQYOUejx40TGcN6SbLhWWhKakIhKCTdn5/GraQmatzWbkER249/xBdG6loxNJfEoqIrXI3Xlh9kb+9NZy6pnx5x8O4sK07jo6kaShpCJSS77etZffTFvEp6u3c9Lh7bnvgkF0a90k7LBEYkpJRaSGuTuvpG/irhnLKXHnnvMG8uPhesSvJCclFZEatCk7n9+9tphPVm3nuN5tuf+CY/TME0lqSioiNaD0vpMH3vuKlHrGXWMGcOmIw6hXT0cnktyUVERibPnmXG55dRELM3I47ciO3HXuQLrq3InUEUoqIjFSUFjMI/9ezRMfraFVkwb83yVDOGdQF507kTpFSUUkBuasy+aWfyxibdYezh/ajdvP7k+bZg3DDkuk1impiByCvIJC7ntnBc/P2kj3Nk2YcvVwTu7XIeywREKjpCJyENydGYs2c9eMZWzfvY9xJ/XiF6P60bSh/qSkbgvlL8DM1gN5QDFQ5O5pZtYWmAr0BNYDF7n7Tot0SD8EnAXkA1e6+5fBesYCtwWrvdvdJ9dmO6RuWr99D7e/voRPVm1nYLeWPHVFGsf0aB12WCJxIcx/q0519+1Rn28B3nf3e83sluDzb4Azgb7BawTwODAiSEJ3AGmAA/PMbLq776zNRkjdsa+omCc+XMujH66mYUo97vx+fy4/vicpukxY5BvxdKw+BhgZTE8GPiSSVMYAU9zdgVlm1trMugR1Z7p7NoCZzQRGAy/VbthSF3y6aju3v76Eddv3cM6gLtx+Tn86tdQAkCJlhZVUHHjPzBz4m7s/CXRy980A7r7ZzDoGdbsBm6KWzQjKKir/FjMbD4wHSE1NjWU7JMltyyvg7hnLmb4wk8PaNdWJeJEqhJVUTnT3zCBxzDSzFZXULa9vwSsp/3ZhJGk9CZCWllZuHZFoRcUlvDB7I395byX7Cku48bS+TBjZh8YNUsIOTSSuhZJU3D0zeN9mZq8Bw4GtZtYlOErpAmwLqmcAPaIW7w5kBuUjy5R/WMOhSx3w+ert/OGNZazcmsdJh7fnj2MG0LtD87DDEkkI9Wp7g2bWzMxalE4Do4AlwHRgbFBtLPB6MD0duMIijgNygm6yd4FRZtbGzNoE63m3FpsiSSZjZz4/fWEeP356Nnv2F/HEZcfy3LjhSigiByCMI5VOwGvB0BX1gRfd/R0zmwu8YmbjgI3AhUH9t4hcTryayCXFVwG4e7aZ3QXMDer9sfSkvciB2Lu/mCc+WsMTH63BDH7xvX785OTe6uoSOQgWuaiq7khLS/P09PSww5A44O68vWQL97y5nK937eWcQV347VlH6cFZIuUws3nunlZVvXi6pFik1qzYkssfpi/ji7U7OLJzC14efxzH9W4XdlgiCU9JReqUbbkFPDjzK15J30TLJg2469yBXDKsB/VTav30okhSUlKROiF/fxFPfbyOv328hsLiEq46sRc/++7htG6qkYRFYklJRZJacYnz6pcZPPDeSrbm7uOsozvz6zOOpGf7ZmGHJpKUlFQkaX26ajv3vLWc5ZtzGdyjNY/+eChpPduGHZZIUlNSkaSzNDOH+99dyYcrs+jepomewChSi5RUJGms276HB2d+xRsLM2nVpAG/O+tIxp7Qk0b1db+JSG1RUpGEtyWngIfeX8Ur6ZtomFKPG049nJ+c3JtWTRqEHZpInaOkIglr5579PP7RGiZ/vp4Sdy4bkcr13z2cji00JL1IWJRUJOHkFRTy7GfreerjtezeX8R5Q7px8+n96NG2adihidR5SiqSMPIKCpn02Xqe/nQdOXsL+V7/Tvxy1BEc0blF2KGJSEBJReJebkEhk6OSyelHdeR/TuvLoO56LrxIvFFSkbiVW3pk8slacgtGkFYvAAAOAUlEQVSKOP2ojtx4Wj+O7t4q7NBEpAJKKhJ3cvILmfxFdDLpxI2n9VUyEUkASioSN7bmFvDMp+t4YdYG9uwvVjIRSUBKKhK6ddv38OTHa3h13tcUlZRwzqCuXHdKH/p3bRl2aCJygJRUJDSLM3J44qM1vLVkMw1S6nHRsO6M/04fUtvp0mCRRKWkIrXK3flk1Xae+mQtn6zaTotG9ZlwSh+uOrEXHVo0Cjs8ETlESipSKwoKi3lt/tdM/HQdq7btpkOLRtxy5pH8eEQqLRtrOBWRZKGkIjVqS04Bz81az4uzN7Izv5ABXVvy4EXHcPagLhroUSQJKalIjViUsYtnPl3Hm4s2U+zOqP6dGHdSb4b1bKMh6EWSmJKKxExBYTEzFm3mhdkbmL9xF80b1WfsCT0Ze3xPnXwXqSOUVOSQrd62mxdnb2TavE3kFhTRp0Mzfn9Ofy5M604LnS8RqVOUVOSg7C8q4d2lW3hh9gZmrc2mQYoxemAXLh2RyohebdXFJVJHKanIAVm1NY9pX2bw6rwMtu/eT/c2Tfj16CO4KK0H7ZvrkmCRuk5JRaq0K38/byzMZNq8DBZm5JBSz/jukR25dEQqJ/ftQL16OioRkQglFSlXUXEJH6/KYtq8DP61bBv7i0s4snMLbjv7KMYM7qYbFUWkXEoq8g13Z2FGDjMWZvL6wkyy8vbRtllDLj0ulR8O7c6Ari11rkREKqWkUse5O0szc3ljUSZvLtpMxs69NEgxRh7RkQuO7c6pR3SkYf16YYcpIglCSaUOcndWbMljRpBI1u/Ip34946S+7bnxtL6MGtCZVk10KbCIHDgllTpk1dY83li0mTcXZbImaw8p9YwT+rTjulP6cMaAzrRp1jDsEEUkwSmpJLmc/EL+MT+DqXM3sWJLHvUMRvRqx9Un9WL0gM6002XAIhJDSipJKq+gkLeXbOGuN5aRt6+IY3q05g8/GMCZR3emY4vGYYcnIklKSSVJ5BYUkr4+m1lrs5m9dgeLv86hxOHYw9rwxzEDGNBVj+QVkZqnpJKA3J1N2Xv5cuNO5m/cybyNO1mWmUuJQ8OUegzu0ZrrTz2cEb3acVzvttRP0dVbIlI7lFQSQP7+IhZuymH+pp18uWEXCzbtZPvu/QA0bZjCMd1b87Pv9mVE77YMTW1D4wZ6TomIhENJJc7k5BeyNDOHpZm537yvydpNiUfm927fjFP6dWRIamuGprahX6fmOhIRkbihpBKSgsJi1mbtYdW2PNZs282KLXkszczl6117v6nTqWUjBnZtxZkDOzMktQ2De7TWZb8iEtcSPqmY2WjgISAFeNrd7w05pG8UFZewOaeATdn5bNqZz/od+azaupvV2/LYmJ3/zdFHPYPD2jVjcGprLj0ulQFdWzGga0uN+isiCSehk4qZpQCPAt8DMoC5Zjbd3ZfV9Lb3FRWzc08h2/IKyMrbx7a8fWzL3cfmnL1s2pnPpuy9ZO7aS1Fp5gAapBi92jdjQNdW/GBwN/p2bE7fTs3p2a6ZzoOISFJI6KQCDAdWu/taADN7GRgDxDypjJs0l6+25bG7oIg9+4rZX1xSbr12zRrSo21TjunRmu8f04UebZqS2rYpPdo2pUurxjr/ISJJLdGTSjdgU9TnDGBE2UpmNh4YD5CamnpQG+rZvhmtmjSgWaP6NGtUnxaN69OqSQM6tmhEx5aN6dCiEe2bN6RRfR1xiEjdlehJpbxx2P1bBe5PAk8CpKWlfWt+ddx+Tv+DWUxEpE5J9L6YDKBH1OfuQGZIsYiI1HmJnlTmAn3NrJeZNQQuBqaHHJOISJ2V0N1f7l5kZjcA7xK5pHiiuy8NOSwRkToroZMKgLu/BbwVdhwiIpL43V8iIhJHlFRERCRmlFRERCRmlFRERCRmzP2g7gVMWGaWBWw4yMXbA9tjGE6Y1Jb4pLbEn2RpBxxaWw5z9w5VVapzSeVQmFm6u6eFHUcsqC3xSW2JP8nSDqidtqj7S0REYkZJRUREYkZJ5cA8GXYAMaS2xCe1Jf4kSzugFtqicyoiIhIzOlIREZGYUVIREZGYUVKpBjMbbWYrzWy1md0SdjwHyszWm9liM1tgZulBWVszm2lmq4L3NmHHWR4zm2hm28xsSVRZubFbxMPBflpkZkPDi/zbKmjLnWb2dbBvFpjZWVHzfhu0ZaWZnRFO1OUzsx5m9oGZLTezpWZ2Y1CecPumkrYk3L4xs8ZmNsfMFgZt+UNQ3svMZgf7ZWrwqBDMrFHweXUwv+chB+HuelXyIjKk/hqgN9AQWAj0DzuuA2zDeqB9mbI/A7cE07cA94UdZwWxnwwMBZZUFTtwFvA2kSeCHgfMDjv+arTlTuCX5dTtH/yuNQJ6Bb+DKWG3ISq+LsDQYLoF8FUQc8Ltm0raknD7Jvj5Ng+mGwCzg5/3K8DFQfkTwIRg+qfAE8H0xcDUQ41BRypVGw6sdve17r4feBkYE3JMsTAGmBxMTwbODTGWCrn7x0B2meKKYh8DTPGIWUBrM+tSO5FWrYK2VGQM8LK773P3dcBqIr+LccHdN7v7l8F0HrAc6EYC7ptK2lKRuN03wc93d/CxQfBy4LvAtKC87H4p3V/TgNPMrLzHtFebkkrVugGboj5nUPkvXDxy4D0zm2dm44OyTu6+GSJ/VEDH0KI7cBXFnqj76oagS2hiVDdkwrQl6DIZQuS/4oTeN2XaAgm4b8wsxcwWANuAmUSOpHa5e1FQJTreb9oSzM8B2h3K9pVUqlZe1k6067BPdPehwJnA9WZ2ctgB1ZBE3FePA32AwcBm4IGgPCHaYmbNgVeBm9w9t7Kq5ZTFVXvKaUtC7ht3L3b3wUB3IkdQR5VXLXiPeVuUVKqWAfSI+twdyAwploPi7pnB+zbgNSK/aFtLux+C923hRXjAKoo94faVu28NvgRKgKf4TzdK3LfFzBoQ+RJ+wd3/ERQn5L4pry2JvG8A3H0X8CGRcyqtzaz0Sb/R8X7TlmB+K6rfRVsuJZWqzQX6BldPNCRyMmt6yDFVm5k1M7MWpdPAKGAJkTaMDaqNBV4PJ8KDUlHs04ErgiuNjgNySrti4lWZ8wrnEdk3EGnLxcHVOb2AvsCc2o6vIkG/+zPAcnd/MGpWwu2bitqSiPvGzDqYWetguglwOpFzRB8AFwTVyu6X0v11AfBvD87aH7Swr1ZIhBeRK1e+ItI3eWvY8Rxg7L2JXKmyEFhaGj+RftP3gVXBe9uwY60g/peIdD0UEvmvalxFsRM5lH802E+LgbSw469GW54LYl0U/IF3iap/a9CWlcCZYcdfpi0nEekmWQQsCF5nJeK+qaQtCbdvgEHA/CDmJcDvg/LeRBLfauDvQKOgvHHweXUwv/ehxqBhWkREJGbU/SUiIjGjpCIiIjGjpCIiIjGjpCIiIjGjpCIiIjGjpCJJwcw+D957mtmPY7zu35W3rZpiZuea2e9raN2/q7rWAa/zaDObFOv1SmLSJcWSVMxsJJGRZc85gGVS3L24kvm73b15LOKrZjyfAz9w9+2HuJ5vtaum2mJm/wKudveNsV63JBYdqUhSMLPSkVnvBb4TPP/i5mBwvfvNbG4wMOC1Qf2RwTM0XiRygxtm9s9g0M2lpQNvmtm9QJNgfS9Ebyu4O/x+M1tikefV/Chq3R+a2TQzW2FmL5SO/Gpm95rZsiCWv5TTjn7AvtKEYmaTzOwJM/vEzL4ys3OC8mq3K2rd5bXlMos8f2OBmf3NzFJK22hm91jkuRyzzKxTUH5h0N6FZvZx1OrfIDLahNR1Yd8BqpdesXgBu4P3kcCMqPLxwG3BdCMgncgzMEYCe4BeUXVL7/5uQuRu5HbR6y5nWz8kMgpsCtAJ2Ejk2RwjiYz22p3IP25fELlruy2RO7BLewhal9OOq4AHoj5PAt4J1tOXyJ34jQ+kXeXFHkwfRSQZNAg+PwZcEUw78P1g+s9R21oMdCsbP3Ai8EbYvwd6hf8qHWBMJFmNAgaZWem4R62IfDnvB+Z45HkYpf7HzM4LpnsE9XZUsu6TgJc80sW01cw+AoYBucG6MwAsMgx5T2AWUAA8bWZvAjPKWWcXIKtM2SseGdRwlZmtBY48wHZV5DTgWGBucCDVhP8MALk/Kr55wPeC6c+ASWb2CvCP/6yKbUDXamxTkpySiiQ7A37m7u/+V2Hk3MueMp9PB45393wz+5DIEUFV667IvqjpYqC+uxeZ2XAiX+YXAzcQeXhStL1EEkS0sic+nWq2qwoGTHb335Yzr9DdS7dbTPBd4e7XmdkI4GxggZkNdvcdRH5We6u5XUliOqciySaPyCNhS70LTLDI0OaYWb9gtOayWgE7g4RyJJHhwksVli5fxsfAj4LzGx2IPC64wtFqLfK8jlbu/hZwE5HndJS1HDi8TNmFZlbPzPoQGRhw5QG0q6zotrwPXGBmHYN1tDWzwypb2Mz6uPtsd/89sJ3/DAHfj/+M4it1mI5UJNksAorMbCGR8xEPEel6+jI4WZ5F+Y9Ofge4zswWEfnSnhU170lgkZl96e6XRpW/BhxPZARoB37t7luCpFSeFsDrZtaYyFHCzeXU+Rh4wMws6khhJfARkfM217l7gZk9Xc12lfVfbTGz24g8FbQekdGTrwc2VLL8/WbWN4j//aDtAKcCb1Zj+5LkdEmxSJwxs4eInPT+V3D/xwx3n1bFYqExs0ZEkt5J/p9H1kodpe4vkfjzJ6Bp2EEcgFTgFiUUAR2piIhIDOlIRUREYkZJRUREYkZJRUREYkZJRUREYkZJRUREYub/A1lNeKJBDo17AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Test Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# run the model \n",
    "parameters = model(inputX, inputY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
