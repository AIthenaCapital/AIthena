{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the package working or not\n",
    "###  - test tensorflow and pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date  Price        RSI  Stedev from 20 MA  MACD n.f  50MA_N.F.  \\\n",
      "0 2011-12-16   3.25  51.415094           0.591527  1.594689   0.500194   \n",
      "1 2011-12-18   3.25  44.324324           0.516482  1.489778   0.571086   \n",
      "2 2011-12-19   3.50  51.196172           1.311777  1.473728   1.266368   \n",
      "3 2011-12-20   4.75  82.269504           3.461711  1.840524   3.831441   \n",
      "4 2011-12-21   4.38  75.324675           2.180044  1.969366   2.760808   \n",
      "\n",
      "   actions  y-hat  Unnamed: 8   Unnamed: 9  \n",
      "0      NaN      2           1  2157.000000  \n",
      "1      NaN      2           1     0.912437  \n",
      "2      NaN      2           1          NaN  \n",
      "3      NaN      2           1          NaN  \n",
      "4      NaN      2           1          NaN  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('BTC daily_database.xlsx', sheet_name=3)\n",
    "# testing the input is correct or not\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(0,dtype=tf.float32)\n",
    "cost = tf.add(tf.add(w**2,tf.multiply(-10.,w)),25)\n",
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print(sess.run(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.099999994\n"
     ]
    }
   ],
   "source": [
    "sess.run(train)\n",
    "print(sess.run(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.9999886\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    sess.run(train)\n",
    "print(sess.run(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4, 2363)\n",
      "number of training samples = 2363\n",
      "number of variables = 4\n",
      "[[51.41509434 44.32432432 51.19617225 ... 41.54757836 54.30118701\n",
      "  52.88985174]\n",
      " [ 0.59152723  0.51648236  1.31177743 ... -0.22095621 -0.06774514\n",
      "   0.05516699]\n",
      " [ 1.59468902  1.48977812  1.47372773 ... -0.43278934 -0.33627381\n",
      "  -0.24796018]\n",
      " [ 0.50019378  0.57108639  1.26636805 ... -1.09502132 -1.03113801\n",
      "  -0.98767088]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\john liu\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\john liu\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "inputX = df.iloc[:,2:6 ].as_matrix()\n",
    "inputX = inputX.T\n",
    "inputY = df.iloc[:, 7:8].as_matrix()\n",
    "inputY = inputY.T\n",
    "print(\"X_train shape: \" + str(inputX.shape))\n",
    "print(\"number of training samples = \"+ str(inputX.shape[1]))\n",
    "print(\"number of variables = \" + str(inputX.shape[0]))\n",
    "print(inputX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 2, ..., 2, 2, 2]], dtype=int64)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## layer size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_x's shape = 4\n",
      "first layer(n_h)'s shape = 5\n",
      "n_y's output = 1\n"
     ]
    }
   ],
   "source": [
    "n_x = inputX.shape[0] # size of input layer\n",
    "n_h = 5\n",
    "n_y = inputY.shape[0]\n",
    "print(\"n_x's shape = \" + str(n_x))\n",
    "print(\"first layer(n_h)'s shape = \" + str(n_h))\n",
    "print(\"n_y's output = \" + str(n_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create placeholder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    \n",
    "    #Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, shape = [n_x,None])\n",
    "    Y = tf.placeholder(tf.float32, shape = [n_y, None])  \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"Placeholder_2:0\", shape=(4, ?), dtype=float32)\n",
      "(4, ?)\n",
      "Y = Tensor(\"Placeholder_3:0\", shape=(1, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X, Y = create_placeholders(n_x,n_y)\n",
    "print (\"X = \" + str(X))\n",
    "print(X.shape)\n",
    "print (\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def initialize_parameters(n_x, n_h):\n",
    "    #Initializes weight parameters to build a neural network with tensorflow  \n",
    "    #tf.set_random_seed()                              \n",
    "    W1 = tf.get_variable(\"W1\", [n_h,n_x], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    b1 = tf.get_variable(\"b1\", [n_h,1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [10, n_h], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    b2 = tf.get_variable(\"b2\", [10, 1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [25, 10], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    b3 = tf.get_variable(\"b3\", [25, 1], initializer = tf.zeros_initializer())\n",
    "    W4 = tf.get_variable(\"W4\", [10, 25], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    b4 = tf.get_variable(\"b4\", [10,1], initializer = tf.zeros_initializer())\n",
    "    W5 = tf.get_variable(\"W5\", [5, 10], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    b5 = tf.get_variable(\"b5\", [5,1], initializer = tf.zeros_initializer())\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3,\n",
    "                  \"W4\": W4,\n",
    "                  \"b4\": b4,\n",
    "                  \"W5\": W5,\n",
    "                  \"b5\": b5}\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = <tf.Variable 'W1:0' shape=(5, 4) dtype=float32_ref>\n",
      "b1 = <tf.Variable 'b1:0' shape=(5, 1) dtype=float32_ref>\n",
      "W2 = <tf.Variable 'W2:0' shape=(10, 5) dtype=float32_ref>\n",
      "b2 = <tf.Variable 'b2:0' shape=(10, 1) dtype=float32_ref>\n",
      "W3 = <tf.Variable 'W3:0' shape=(25, 10) dtype=float32_ref>\n",
      "b3 = <tf.Variable 'b3:0' shape=(25, 1) dtype=float32_ref>\n",
      "W4 = <tf.Variable 'W4:0' shape=(10, 25) dtype=float32_ref>\n",
      "b4 = <tf.Variable 'b4:0' shape=(10, 1) dtype=float32_ref>\n",
      "W5 = <tf.Variable 'W5:0' shape=(5, 10) dtype=float32_ref>\n",
      "b5 = <tf.Variable 'b5:0' shape=(5, 1) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    parameters = initialize_parameters(n_x, n_h)\n",
    "    print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "    print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "    print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "    print(\"b2 = \" + str(parameters[\"b2\"]))\n",
    "    print(\"W3 = \" + str(parameters[\"W3\"]))\n",
    "    print(\"b3 = \" + str(parameters[\"b3\"]))\n",
    "    print(\"W4 = \" + str(parameters[\"W4\"]))\n",
    "    print(\"b4 = \" + str(parameters[\"b4\"]))\n",
    "    print(\"W5 = \" + str(parameters[\"W5\"]))\n",
    "    print(\"b5 = \" + str(parameters[\"b5\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_matrix(labels, C):\n",
    "    \"\"\"\n",
    "    Creates a matrix where the i-th row corresponds to the ith class number and the jth column\n",
    "                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j) \n",
    "                     will be 1. \n",
    "                     \n",
    "    Arguments:\n",
    "    labels -- vector containing the labels \n",
    "    C -- number of classes, the depth of the one hot dimension\n",
    "    \n",
    "    Returns: \n",
    "    one_hot -- one hot matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a tf.constant equal to C (depth), name it 'C'. (approx. 1 line)\n",
    "    C = tf.constant(C, name = \"C\")\n",
    "    \n",
    "    # Use tf.one_hot, be careful with the axis (approx. 1 line)\n",
    "    one_hot_matrix = tf.one_hot(indices = labels, depth = C,axis  =0)\n",
    "    \n",
    "    # Create the session (approx. 1 line)\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # Run the session (approx. 1 line)\n",
    "    one_hot = sess.run(one_hot_matrix)\n",
    "    \n",
    "    # Close the session (approx. 1 line). See method 1 above.\n",
    "    sess.close()\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot = [[0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "labels = np.array([1,2,3,0,2,1])\n",
    "one_hot = one_hot_matrix(labels, C = 4)\n",
    "print (\"one_hot = \" + str(one_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Y-hat to softmax matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y = \n",
      "[[[0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[1. 1. 1. ... 1. 1. 1.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]]]\n",
      "Y-shape = (5, 1, 2363)\n"
     ]
    }
   ],
   "source": [
    "Y = one_hot_matrix(inputY, C = 5)\n",
    "print(\"Y = \")\n",
    "print(Y)\n",
    "print(\"Y-shape = \" + str(Y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\", \"W4\", \"b4\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z4 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    W4 = parameters['W4']\n",
    "    b4 = parameters['b4']\n",
    "    W5 = parameters['W5']\n",
    "    b5 = parameters['b5'] \n",
    "    \n",
    "    \n",
    "                                                                     # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1,X) , b1 )                               # Z1 = np.dot(W1,  X) + b1\n",
    "    A1 = tf.nn.tanh(Z1)                                              # A1 = sigmoid(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2,A1), b2 )                               # Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = tf.nn.tanh(Z2)                                              # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3,A2), b3)                                # Z3 = np.dot(W3, A2) + b3\n",
    "    A3 = tf.nn.tanh(Z3)                                              # A3 = relu(Z3)\n",
    "    Z4 = tf.add(tf.matmul(W4,A3), b4)                                # Z4 = np.dot(W4, A3) + b4 \n",
    "    A4 = tf.nn.tanh(Z4)                                              # A4 = relu(Z4)\n",
    "    Z5 = tf.add(tf.matmul(W5,A4), b5)                                # Z5 = np.dot(W5, A4) + b5 \n",
    "    return Z5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z5, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z4 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z4\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z5)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    #compute cost\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(4, 1)\n",
    "    parameters = initialize_parameters(4,1)\n",
    "    Z4 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z4, Y)\n",
    "    print(\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "\n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)\n",
    "    mini_batch_size -- size of the mini-batches, integer\n",
    "\n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(seed)            # To make your \"random\" minibatches the same as ours\n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation]\n",
    "    \n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        mini_batch_X = X[:, k*mini_batch_size : (k+1)*mini_batch_size]\n",
    "        mini_batch_Y = Y[:, k*mini_batch_size : (k+1)*mini_batch_size]\n",
    "        ### END CODE HERE ###\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "\n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        mini_batch_X = X[:, num_complete_minibatches*mini_batch_size : m]\n",
    "        mini_batch_Y = Y[:, num_complete_minibatches*mini_batch_size : m]\n",
    "        ### END CODE HERE ###\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "\n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 2363), (1, 2363))"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test(X,Y):\n",
    "    m = X.shape\n",
    "    n = Y.shape\n",
    "    return m, n\n",
    "test(inputX,inputY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the 1st mini_batch_X: (4, 64)\n",
      "shape of the 2nd mini_batch_X: (4, 64)\n",
      "shape of the 3rd mini_batch_X: (4, 64)\n",
      "shape of the last mini_batch_X: (4, 59)\n",
      "shape of the 1st mini_batch_Y: (1, 64)\n",
      "shape of the 2nd mini_batch_Y: (1, 64)\n",
      "shape of the 3rd mini_batch_Y: (1, 64)\n",
      "shape of the last mini_batch_Y: (1, 59)\n",
      "mini batch sanity check: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 4, 4, 4, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_batches = random_mini_batches(inputX, inputY, 64, seed=0)\n",
    "\n",
    "print (\"shape of the 1st mini_batch_X: \" + str(mini_batches[0][0].shape))\n",
    "print (\"shape of the 2nd mini_batch_X: \" + str(mini_batches[1][0].shape))\n",
    "print (\"shape of the 3rd mini_batch_X: \" + str(mini_batches[2][0].shape))\n",
    "print (\"shape of the last mini_batch_X: \" + str(mini_batches[-1][0].shape))\n",
    "print (\"shape of the 1st mini_batch_Y: \" + str(mini_batches[0][1].shape))\n",
    "print (\"shape of the 2nd mini_batch_Y: \" + str(mini_batches[1][1].shape)) \n",
    "print (\"shape of the 3rd mini_batch_Y: \" + str(mini_batches[2][1].shape))\n",
    "print (\"shape of the last mini_batch_Y: \" + str(mini_batches[-1][1].shape))\n",
    "print (\"mini batch sanity check: \")\n",
    "mini_batches[0][1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, learning_rate = 0.1,\n",
    "          num_epochs = 1500, minibatch_size = 64, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    \n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X.shape                                # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y.shape[0]                                  # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "\n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters(n_x, n_h)\n",
    "\n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    Z4 = forward_propagation(X, parameters)\n",
    "\n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    cost = compute_cost(Z4,Y)\n",
    "\n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "\n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "\n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(inputX, inputY, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "\n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "\n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "\n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z4), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: inputX, Y: inputY}))\n",
    "\n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 17.318079\n",
      "Cost after epoch 100: 17.210659\n",
      "Cost after epoch 200: 17.192561\n",
      "Cost after epoch 300: 17.177298\n",
      "Cost after epoch 400: 17.164774\n",
      "Cost after epoch 500: 17.151230\n",
      "Cost after epoch 600: 17.135504\n",
      "Cost after epoch 700: 17.118442\n",
      "Cost after epoch 800: 17.101338\n",
      "Cost after epoch 900: 17.084198\n",
      "Cost after epoch 1000: 17.070156\n",
      "Cost after epoch 1100: 17.054154\n",
      "Cost after epoch 1200: 17.044702\n",
      "Cost after epoch 1300: 17.031670\n",
      "Cost after epoch 1400: 17.014822\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Test Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# run the model \n",
    "parameters = model(inputX, inputY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
