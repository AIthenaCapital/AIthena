{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date  Price       RSI  Stedev from 20 MA  MACD n.f  50MA_N.F.  \\\n",
      "0 2011-12-16   3.25  0.514151           0.591527  1.594689   0.500194   \n",
      "1 2011-12-18   3.25  0.443243           0.516482  1.489778   0.571086   \n",
      "2 2011-12-19   3.50  0.511962           1.311777  1.473728   1.266368   \n",
      "3 2011-12-20   4.75  0.822695           3.461711  1.840524   3.831441   \n",
      "4 2011-12-21   4.38  0.753247           2.180044  1.969366   2.760808   \n",
      "\n",
      "   20D PMO  35D PMO        ADX  actions  y-hat  Unnamed: 11  Unnamed: 12  \n",
      "0    3.270     0.59  69.772809      NaN      2            1  2157.000000  \n",
      "1    3.690     0.46  70.038037      NaN      2            1     0.912437  \n",
      "2    4.275     0.67  70.475308      NaN      2            1          NaN  \n",
      "3    5.140     1.55  68.503186      NaN      2            1          NaN  \n",
      "4    5.910     1.28  66.671929      NaN      2            1          NaN  \n"
     ]
    }
   ],
   "source": [
    "dfz = pd.read_excel('BTC daily_database.xlsx', sheet_name=0)\n",
    "# testing the input is correct or not\n",
    "print(dfz.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomize sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffler(filename):\n",
    "  dfs = pd.read_excel(filename, sheet_name=0, header=0)\n",
    "  # return the pandas dataframe\n",
    "  return dfs.reindex(np.random.permutation(dfs.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date    Price       RSI  Stedev from 20 MA  MACD n.f  50MA_N.F.  \\\n",
      "1520 2016-02-17   407.51  0.686109           2.260056  0.354841   0.176178   \n",
      "740  2013-12-26   679.01  0.367948          -0.516853 -1.315067  -0.116348   \n",
      "720  2013-12-06  1020.51  0.659549           0.769497  1.269491   1.588047   \n",
      "130  2012-04-25     5.12  0.608333           0.747216  1.446671   0.752339   \n",
      "338  2012-11-19    11.51  0.809859           2.058762  0.471798   0.195998   \n",
      "\n",
      "      20D PMO  35D PMO        ADX  actions  y-hat  Unnamed: 11  Unnamed: 12  \n",
      "1520   -3.035    -0.10  16.041618      NaN      2            1          NaN  \n",
      "740    29.365     1.03  41.386650      NaN      2            1          NaN  \n",
      "720    49.730     5.18  20.113360      NaN      2            1          NaN  \n",
      "130     0.090     0.16  12.498117      NaN      2            1          NaN  \n",
      "338    -2.885    -0.05  54.075682      NaN      2            1          NaN  \n"
     ]
    }
   ],
   "source": [
    "df = shuffler('BTC daily_database.xlsx')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputX shape: (7, 2363)\n",
      "number of training samples = 2363\n",
      "number of variables = 7\n",
      "[[ 0.68610931  0.36794782  0.65954871 ...  0.35450509  0.92620019\n",
      "   0.59205372]\n",
      " [ 2.26005602 -0.51685313  0.76949726 ... -0.92234658  2.59940663\n",
      "   0.43743642]\n",
      " [ 0.35484066 -1.3150666   1.26949123 ... -1.1909118   1.88909038\n",
      "   0.38748341]\n",
      " ...\n",
      " [-3.035      29.365      49.73       ... -2.125       1.55\n",
      "   6.7       ]\n",
      " [-0.1         1.03        5.18       ... -0.35        0.44\n",
      "   0.85      ]\n",
      " [16.04161786 41.38664988 20.11336045 ... 53.09190026 21.1527685\n",
      "  27.41095775]]\n",
      "(1, 2363)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\john liu\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\john liu\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "inputX = df.iloc[:,2:9 ].as_matrix()\n",
    "inputX = inputX.T\n",
    "inputY = df.iloc[:, 10:11].as_matrix()\n",
    "inputY = inputY.T\n",
    "print(\"inputX shape: \" + str(inputX.shape))\n",
    "print(\"number of training samples = \"+ str(inputX.shape[1]))\n",
    "print(\"number of variables = \" + str(inputX.shape[0]))\n",
    "print(inputX)\n",
    "print(inputY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 2, ..., 2, 2, 2]], dtype=int64)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperating to train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX's shape(7, 1893)\n",
      "testX's shape(7, 470)\n",
      "trainX's shape(1, 1893)\n",
      "testY's shape(1, 470)\n"
     ]
    }
   ],
   "source": [
    "trainX = inputX[:, : -470]\n",
    "trainY = inputY[:, : -470]\n",
    "testX = inputX[:, -470: ]\n",
    "testY = inputY[:, -470: ]\n",
    "print(\"trainX's shape\" + str(trainX.shape))\n",
    "print(\"testX's shape\" + str(testX.shape))\n",
    "print(\"trainX's shape\" + str(trainY.shape))\n",
    "print(\"testY's shape\" + str(testY.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer size inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_x's shape = 7\n",
      "first layer(n_h)'s shape = 10\n",
      "n_y's output = 1\n"
     ]
    }
   ],
   "source": [
    "n_x = inputX.shape[0] # size of input layer\n",
    "n_h = 10\n",
    "n_y = inputY.shape[0]\n",
    "print(\"n_x's shape = \" + str(n_x))\n",
    "print(\"first layer(n_h)'s shape = \" + str(n_h))\n",
    "print(\"n_y's output = \" + str(n_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create placeholder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    \n",
    "    #Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, shape = [n_x,None])\n",
    "    Y = tf.placeholder(tf.float32, shape = [n_y, 1, None])  \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"Placeholder_2:0\", shape=(7, ?), dtype=float32)\n",
      "(7, ?)\n",
      "Y = Tensor(\"Placeholder_3:0\", shape=(1, 1, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X, Y = create_placeholders(n_x,n_y)\n",
    "print (\"X = \" + str(X))\n",
    "print(X.shape)\n",
    "print (\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def initialize_parameters(n_x, n_h):\n",
    "    #Initializes weight parameters to build a neural network with tensorflow  \n",
    "    #tf.set_random_seed()                              \n",
    "    W1 = tf.get_variable(\"W1\", [n_h,n_x], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    b1 = tf.get_variable(\"b1\", [n_h,1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [10, n_h], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    b2 = tf.get_variable(\"b2\", [10, 1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [25, 10], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    b3 = tf.get_variable(\"b3\", [25, 1], initializer = tf.zeros_initializer())\n",
    "    W4 = tf.get_variable(\"W4\", [10, 25], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    b4 = tf.get_variable(\"b4\", [10,1], initializer = tf.zeros_initializer())\n",
    "    W5 = tf.get_variable(\"W5\", [5, 10], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    b5 = tf.get_variable(\"b5\", [5,1], initializer = tf.zeros_initializer())\n",
    "    #W6 = tf.get_variable(\"W6\", [5, 10], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    #b6 = tf.get_variable(\"b6\", [5,1], initializer = tf.zeros_initializer())\n",
    "    #W7 = tf.get_variable(\"W7\", [5, 10], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    #b7 = tf.get_variable(\"b7\", [5,1], initializer = tf.zeros_initializer())\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3,\n",
    "                  \"W4\": W4,\n",
    "                  \"b4\": b4,\n",
    "                  \"W5\": W5,\n",
    "                  \"b5\": b5}\n",
    "                  #\"W6\": W6,\n",
    "                  #\"b6\": b6,\n",
    "                  #\"W7\": W7,\n",
    "                  #\"b7\": b7}\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = <tf.Variable 'W1:0' shape=(10, 7) dtype=float32_ref>\n",
      "b1 = <tf.Variable 'b1:0' shape=(10, 1) dtype=float32_ref>\n",
      "W2 = <tf.Variable 'W2:0' shape=(10, 10) dtype=float32_ref>\n",
      "b2 = <tf.Variable 'b2:0' shape=(10, 1) dtype=float32_ref>\n",
      "W3 = <tf.Variable 'W3:0' shape=(25, 10) dtype=float32_ref>\n",
      "b3 = <tf.Variable 'b3:0' shape=(25, 1) dtype=float32_ref>\n",
      "W4 = <tf.Variable 'W4:0' shape=(10, 25) dtype=float32_ref>\n",
      "b4 = <tf.Variable 'b4:0' shape=(10, 1) dtype=float32_ref>\n",
      "W5 = <tf.Variable 'W5:0' shape=(5, 10) dtype=float32_ref>\n",
      "b5 = <tf.Variable 'b5:0' shape=(5, 1) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    parameters = initialize_parameters(n_x, n_h)\n",
    "    print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "    print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "    print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "    print(\"b2 = \" + str(parameters[\"b2\"]))\n",
    "    print(\"W3 = \" + str(parameters[\"W3\"]))\n",
    "    print(\"b3 = \" + str(parameters[\"b3\"]))\n",
    "    print(\"W4 = \" + str(parameters[\"W4\"]))\n",
    "    print(\"b4 = \" + str(parameters[\"b4\"]))\n",
    "    print(\"W5 = \" + str(parameters[\"W5\"]))\n",
    "    print(\"b5 = \" + str(parameters[\"b5\"]))\n",
    "    #print(\"W6 = \" + str(parameters[\"W6\"]))\n",
    "    #print(\"b6 = \" + str(parameters[\"b6\"]))\n",
    "    #print(\"W7 = \" + str(parameters[\"W7\"]))\n",
    "    #print(\"b7 = \" + str(parameters[\"b7\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_matrix(labels, C):\n",
    "    \"\"\"\n",
    "    Creates a matrix where the i-th row corresponds to the ith class number and the jth column\n",
    "                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j) \n",
    "                     will be 1. \n",
    "                     \n",
    "    Arguments:\n",
    "    labels -- vector containing the labels \n",
    "    C -- number of classes, the depth of the one hot dimension\n",
    "    \n",
    "    Returns: \n",
    "    one_hot -- one hot matrix\n",
    "    \"\"\"\n",
    "    # Create a tf.constant equal to C (depth), name it 'C'. (approx. 1 line)\n",
    "    C = tf.constant(C, name = \"C\")\n",
    "    \n",
    "    # Use tf.one_hot, be careful with the axis (approx. 1 line)\n",
    "    one_hot_matrix = tf.one_hot(indices = labels, depth = C,axis  =0)\n",
    "    \n",
    "    # Create the session (approx. 1 line)\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # Run the session (approx. 1 line)\n",
    "    one_hot = sess.run(one_hot_matrix)\n",
    "    \n",
    "    # Close the session (approx. 1 line). See method 1 above.\n",
    "    sess.close()\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot = [[0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "labels = np.array([1,2,3,0,2,1])\n",
    "one_hot = one_hot_matrix(labels, C = 4)\n",
    "print (\"one_hot = \" + str(one_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Y-hat to softmax matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y = \n",
      "[[[0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[1. 1. 1. ... 1. 1. 1.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]]]\n",
      "trainY-shape = (5, 1, 1893)\n",
      "testY-shape = (5, 1, 470)\n"
     ]
    }
   ],
   "source": [
    "trainY = one_hot_matrix(trainY, C = 5)\n",
    "testY = one_hot_matrix(testY, C = 5) \n",
    "print(\"Y = \")\n",
    "print(trainY)\n",
    "print(\"trainY-shape = \" + str(trainY.shape))\n",
    "print(\"testY-shape = \" + str(testY.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\", \"W4\", \"b4\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z4 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    W4 = parameters['W4']\n",
    "    b4 = parameters['b4']\n",
    "    W5 = parameters['W5']\n",
    "    b5 = parameters['b5'] \n",
    "    #W6 = parameters['W6']\n",
    "    #b6 = parameters['b6'] \n",
    "    #W7 = parameters['W7']\n",
    "    #b7 = parameters['b7'] \n",
    "                                                                     \n",
    "    Z1 = tf.add(tf.matmul(W1,X) , b1 )                              \n",
    "    A1 = tf.nn.tanh(Z1)                                                  \n",
    "    Z2 = tf.add(tf.matmul(W2,A1), b2 )                               \n",
    "    A2 = tf.nn.sigmoid(Z2)                                                  \n",
    "    Z3 = tf.add(tf.matmul(W3,A2), b3)\n",
    "    A3 = tf.nn.selu(Z3)                                         \n",
    "    Z4 = tf.add(tf.matmul(W4,A3), b4)                                \n",
    "    A4 = tf.nn.selu(Z4)                                                  \n",
    "    Z5 = tf.add(tf.matmul(W5,A4), b5)                                 \n",
    "    #A5 = tf.nn.tanh(Z5)                                              \n",
    "    #Z6 = tf.add(tf.matmul(W6,A5), b6)                                 \n",
    "    #A6 = tf.nn.relu(Z6)                                              \n",
    "    #Z7 = tf.add(tf.matmul(W7,A6), b7)                                \n",
    "    return Z5\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z4 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z4\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    #compute cost\n",
    "    cost = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = Tensor(\"Sum:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(4, 1)\n",
    "    parameters = initialize_parameters(4,1)\n",
    "    Z1 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z1, Y)\n",
    "    print(\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Mini-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "\n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)\n",
    "    mini_batch_size -- size of the mini-batches, integer\n",
    "\n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(seed)            # To make your \"random\" minibatches the same as ours\n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    #permutation = list(np.random.permutation(m))\n",
    "    #shuffled_X = X[:, permutation]\n",
    "    #shuffled_Y = Y[:, 1, permutation]\n",
    "    \n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        mini_batch_X = X[:, k*mini_batch_size : (k+1)*mini_batch_size]\n",
    "        mini_batch_Y = Y[:,:, k*mini_batch_size : (k+1)*mini_batch_size]\n",
    "        ### END CODE HERE ###\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "\n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        mini_batch_X = X[:, num_complete_minibatches*mini_batch_size : m]\n",
    "        mini_batch_Y = Y[:,:, num_complete_minibatches*mini_batch_size : m]\n",
    "        ### END CODE HERE ###\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "\n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the 1st mini_batch_X: (7, 64)\n",
      "shape of the 2nd mini_batch_X: (7, 64)\n",
      "shape of the 3rd mini_batch_X: (7, 64)\n",
      "shape of the last mini_batch_X: (7, 37)\n",
      "shape of the 1st mini_batch_Y: (5, 1, 64)\n",
      "shape of the 2nd mini_batch_Y: (5, 1, 64)\n",
      "shape of the 3rd mini_batch_Y: (5, 1, 64)\n",
      "shape of the last mini_batch_Y: (5, 1, 37)\n"
     ]
    }
   ],
   "source": [
    "mini_batches = random_mini_batches(trainX, trainY, 64, seed=0)\n",
    "\n",
    "print (\"shape of the 1st mini_batch_X: \" + str(mini_batches[0][0].shape))\n",
    "print (\"shape of the 2nd mini_batch_X: \" + str(mini_batches[1][0].shape))\n",
    "print (\"shape of the 3rd mini_batch_X: \" + str(mini_batches[2][0].shape))\n",
    "print (\"shape of the last mini_batch_X: \" + str(mini_batches[-1][0].shape))\n",
    "print (\"shape of the 1st mini_batch_Y: \" + str(mini_batches[0][1].shape))\n",
    "print (\"shape of the 2nd mini_batch_Y: \" + str(mini_batches[1][1].shape)) \n",
    "print (\"shape of the 3rd mini_batch_Y: \" + str(mini_batches[2][1].shape))\n",
    "print (\"shape of the last mini_batch_Y: \" + str(mini_batches[-1][1].shape))\n",
    "#print (\"mini batch sanity check: \")\n",
    "#mini_batches[0][1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(trainX, trainY, testX, testY, learning_rate = 0.0013,\n",
    "          num_epochs = 2200, minibatch_size = 64, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    \n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = trainX.shape                                # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = trainY.shape[0]                                  # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "\n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters(n_x, n_h)\n",
    "\n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    Z = forward_propagation(X, parameters)\n",
    "    \n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    cost = compute_cost(Z,Y)\n",
    "\n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "\n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "\n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(trainX, trainY, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "\n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "\n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "\n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: trainX, Y: trainY}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: testX, Y: testY}))\n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 40.995368\n",
      "Cost after epoch 100: 17.838879\n",
      "Cost after epoch 200: 16.634237\n",
      "Cost after epoch 300: 15.977861\n",
      "Cost after epoch 400: 15.295133\n",
      "Cost after epoch 500: 14.748024\n",
      "Cost after epoch 600: 14.312328\n",
      "Cost after epoch 700: 13.871598\n",
      "Cost after epoch 800: 13.363634\n",
      "Cost after epoch 900: 12.996505\n",
      "Cost after epoch 1000: 12.746000\n",
      "Cost after epoch 1100: 12.563649\n",
      "Cost after epoch 1200: 12.363471\n",
      "Cost after epoch 1300: 12.164902\n",
      "Cost after epoch 1400: 11.977709\n",
      "Cost after epoch 1500: 11.776416\n",
      "Cost after epoch 1600: 11.516051\n",
      "Cost after epoch 1700: 11.276219\n",
      "Cost after epoch 1800: 11.034464\n",
      "Cost after epoch 1900: 10.849441\n",
      "Cost after epoch 2000: 10.593286\n",
      "Cost after epoch 2100: 10.420642\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy: 0.945589\n",
      "Test Accuracy: 0.9170213\n"
     ]
    }
   ],
   "source": [
    "# run the model \n",
    "parameters = model(trainX, trainY, testX,testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
